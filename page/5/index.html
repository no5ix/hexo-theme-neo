<!DOCTYPE html>



  


<html class="theme-next mist use-motion" lang="zh-Hans">
<head><meta name="generator" content="Hexo 3.9.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
<meta name="theme-color" content="#222">

<script>
    (function(){
        if(''){
          // alert('此文章并不公开, 输入文章密码方可阅读');
          var password = prompt('此文章并不公开, 输入文章密码方可阅读');
          if (password !== ''){
            if (password != null) // 如果用户点击了确认而且密码错误的时候, 因为当password == null的时候说明用户点了取消
            {
              alert('Error!');
            }
            if (history.length > 1)
            {
              history.back();
            }
            else
            {
              window.location.href = "about:blank";
            }
          }
        }
    })();
</script>








<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">















  
  
  <link href="/lib/fancybox/dist/jquery.fancybox.css?v=3.2.10" rel="stylesheet" type="text/css">







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css">

<link href="/css/main.css?v=5.1.2" rel="stylesheet" type="text/css">


  <meta name="keywords" content="Hexo, NexT">








  <link rel="shortcut icon" type="image/x-icon" href="/images/favicon.ico?v=5.1.2">






<meta name="description" content="推荐使用Chrome/Firefox/Safari阅读本博客. 以前的老笔记将会一篇一篇慢慢整理为博客, 这既启发了他人, 也锻炼了自己的描述交流能力.">
<meta property="og:type" content="website">
<meta property="og:title" content="烫">
<meta property="og:url" content="https://hulinhong.com/page/5/index.html">
<meta property="og:site_name" content="烫">
<meta property="og:description" content="推荐使用Chrome/Firefox/Safari阅读本博客. 以前的老笔记将会一篇一篇慢慢整理为博客, 这既启发了他人, 也锻炼了自己的描述交流能力.">
<meta property="og:locale" content="zh-Hans">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="烫">
<meta name="twitter:description" content="推荐使用Chrome/Firefox/Safari阅读本博客. 以前的老笔记将会一篇一篇慢慢整理为博客, 这既启发了他人, 也锻炼了自己的描述交流能力.">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Mist',
    sidebar: {"position":"left","display":"post","offset":12,"offset_float":12,"scrollpercent":true,"onmobile":true,"dimmer":true,"body_content_height":0,"display_duration":150},
    local_search: {"enable":true,"trigger":"auto","top_n_per_article":1},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"duration":222,"transition":{"header":"slideDownIn","menu":"slideDownIn","logo":"slideDownIn","post_block_else":"slideDownIn","post_header":"fadeIn","post_body":"fadeIn","coll_header":"slideDownIn","footer":"slideDownIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>








  <title>烫 - 烫烫烫烫烫</title>
  














</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-left 
   page-home 
 ">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">烫</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">烫烫烫烫烫</p>
      
  </div>

  <div class="menu-item sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <div class="menu-item site-search">
    
  
  <form class="site-search-form">
    <span class="search-icon fa fa-search"></span>
    <input type="text" id="local-search-input" class="st-search-input">
    <i id="local-search-close">×</i>
  </form>


<script type="text/javascript" id="local.search.active">
var inputArea       = document.querySelector("#local-search-input");
inputArea.onclick   = function(){ getSearchFile(); this.onclick = null }
inputArea.onkeydown = function(){ if(event.keyCode == 13) return false }
</script>



  </div>
  <div id="local-search-result-pc" class="local-search-result-cls"></div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  
  

  
    <ul id="menu" class="menu menu-left">
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br>
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br>
            
            归档
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br>
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br>
            
            关于
          </a>
        </li>
      

       
    </ul>
  

  
    
  
</nav>



 </div>
    </header>

    <div id="local-search-result-mobile" class="local-search-result-cls"></div>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      
        

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://hulinhong.com/2021/03/13/self_cultivation_cpp/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="no5ix">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/uploads/avatar.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="烫">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2021/03/13/self_cultivation_cpp/" itemprop="url">服务器开发自我修养专栏-CPP要点</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2021-03-13T19:08:06+00:00">
                2021-03-13
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Self-cultivation/" itemprop="url" rel="index">
                    <span itemprop="name">Self-cultivation</span>
                  </a>
                </span>

                
                
              
            </span>
          

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    




    
    
    
    <div class="post-body" itemprop="articleBody">
      
      

      

      
      
        <div class="post-eof"></div>
      

      
      

      
        
          
            <h1 id="C"><a href="#C" class="headerlink" title="C++"></a>C++</h1><p>参考: 看之前一个哥们总结的c++要点 <a href="https://interview.huihut.com/" target="_blank" rel="noopener">https://interview.huihut.com/</a></p>
<ul>
<li><p><code>new</code> 和 <code>delete</code> 为什么要配对用:</p>
<ul>
<li><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">A</span>&#123;</span></span><br><span class="line"><span class="comment">//...</span></span><br><span class="line">&#125;;</span><br><span class="line">A *pa = <span class="keyword">new</span> A();</span><br><span class="line">A *pas = <span class="keyword">new</span> A[NUM]();</span><br></pre></td></tr></table></figure>
</li>
<li><p>delete []pas; //详细流程: delete[] pas 用来释放pas指向的内存！！还逐一调用数组中每个对象的destructor！！</p>
</li>
<li>delete []pa; //会发生什么, 答案是调用未知次数的A的析构函数. 因为delete[]会去通过pa+offset找一个基于pa的偏移量找一个内存里的数据, 他假定这个内存里放了要调用析构的次数n这个数据, 而这个内存里到底是多少是未知的.</li>
<li>delete pas; //哪些指针会变成野指针, 答案是pas和A[0]中的指针会变成野指针. 因为只有这两个指针指向的内存被释放了, 也就是说, 仅释放了pas指针指向的这个数组的全部内存空间, 以及只调用了a[0]对象的析构函数</li>
</ul>
</li>
<li>cqq vec set map list<ul>
<li><a href="/2016/05/17/stl_vector_string/" title="vector和string的内存分配与使用注意点">vector和string的内存分配与使用注意点</a></li>
<li><a href="/2016/04/26/stll_set_map_tutorial/" title="stl关联容器的特性">stl关联容器的特性</a></li>
</ul>
</li>
<li>map的<code>[]</code>和insert的区别?<ul>
<li>insert 含义是：如果key存在，则插入失败，如果key不存在，就创建这个key－value。实例: <code>map.insert((key, value))</code></li>
<li>利用下标操作的含义是：如果这个key存在，就更新value；如果key不存在，就创建这个key－value对 实例：<code>map[key] = value</code></li>
</ul>
</li>
<li>vector的resize和reserve的区别?<ul>
<li>总结: <ul>
<li>resize既分配了空间，也创建了对象，可以通过下标访问。当new_size大于原size, 则resize既修改capacity大小，也修改size大小。否则只修改size大小.</li>
<li>reserve只分配了空间, 也就是说它只修改capacity大小，不修改size大小, 若 new_cap 小于等于当前的 capacity(), 它啥也不干.</li>
</ul>
</li>
<li>resize: 重设容器大小以容纳 count 个元素。<br>  若当前大小大于 count ，则减小容器为其首 count 个元素。<br>  若当前大小小于 count:<ul>
<li>则后附额外的默认插入的元素</li>
<li>则后附额外的 value 的副本</li>
</ul>
</li>
<li>reserve: 增加 vector 的容量到大于或等于 new_cap 的值。若 new_cap 大于当前的 capacity() ，则分配新存储，<strong>否则该方法不做任何事</strong>。reserve() 不更改 vector 的 size 。若 new_cap 大于 capacity() ，则所有迭代器，包含尾后迭代器和所有到元素的引用都被非法化。否则，没有迭代器或引用被非法化。</li>
</ul>
</li>
<li>字节对齐<ul>
<li><a href="/2015/04/12/sizeof_struct/" title="对象模型之内存对齐基础">对象模型之内存对齐基础</a></li>
</ul>
</li>
<li><p>定位new </p>
<ul>
<li><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> <span class="built_in">std</span>;</span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">char</span> buffer[<span class="number">512</span>];   <span class="comment">//chunk of memory内存池</span></span><br><span class="line">    <span class="keyword">int</span> *p2, *p3;</span><br><span class="line">    <span class="comment">//定位new:</span></span><br><span class="line">    p2 = <span class="keyword">new</span> (buffer) <span class="keyword">int</span>[<span class="number">10</span>];</span><br><span class="line">    p2[<span class="number">0</span>] = <span class="number">99</span>;</span><br><span class="line">    p2[<span class="number">1</span>] = <span class="number">88</span>;</span><br><span class="line">    <span class="built_in">cout</span> &lt;&lt; <span class="string">"buffer = "</span> &lt;&lt;(<span class="keyword">void</span> *)buffer &lt;&lt; <span class="built_in">endl</span>; <span class="comment">//内存池地址</span></span><br><span class="line">    <span class="built_in">cout</span> &lt;&lt; <span class="string">"p2 = "</span> &lt;&lt; p2 &lt;&lt; <span class="built_in">endl</span>;             <span class="comment">//定位new指向的地址</span></span><br><span class="line">    <span class="built_in">cout</span> &lt;&lt; <span class="string">"p2[0] = "</span> &lt;&lt; p2[<span class="number">0</span>] &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line">    p3 = <span class="keyword">new</span> (buffer) <span class="keyword">int</span>[<span class="number">2</span>];</span><br><span class="line">    p3[<span class="number">0</span>] = <span class="number">1</span>;</span><br><span class="line">    p3[<span class="number">1</span>] = <span class="number">2</span>;</span><br><span class="line">    <span class="built_in">cout</span> &lt;&lt; <span class="string">"p3 = "</span> &lt;&lt; p3 &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line">    <span class="built_in">cout</span> &lt;&lt; <span class="string">"p2[0] = "</span> &lt;&lt; p2[<span class="number">0</span>] &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line">    <span class="built_in">cout</span> &lt;&lt; <span class="string">"p2[1] = "</span> &lt;&lt; p2[<span class="number">1</span>] &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line">    <span class="built_in">cout</span> &lt;&lt; <span class="string">"p2[2] = "</span> &lt;&lt; p2[<span class="number">2</span>] &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line">    <span class="built_in">cout</span> &lt;&lt; <span class="string">"p2[3] = "</span> &lt;&lt; p2[<span class="number">3</span>] &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>结果发现p3和p2还有buffer都是使用同样的内存地址，符合指定地址的内存块，而且p3在指定位置覆盖了p2的前两处的值。</p>
</li>
</ul>
</li>
<li>c++一个空类会生成什么 (答: 默认构造/析构(非虚)/赋值运算符/默认拷贝/取地址/const取地址) </li>
<li><p>虚函数（virtual）可以是内联函数（inline）吗？</p>
<ul>
<li>虚函数可以是内联函数，内联是可以修饰虚函数的，但是当虚函数表现多态性的时候不能内联。</li>
<li>内联是在编译器建议编译器内联，而虚函数的多态性在运行期，编译器无法知道运行期调用哪个代码，因此虚函数表现为多态性时（运行期）不可以内联。</li>
<li>inline virtual 唯一可以内联的时候是：编译器知道所调用的对象是哪个类（如 Base::who()），这只有在编译器具有实际对象而不是对象的指针或引用时才会发生。<br>虚函数内联使用:<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 此处的虚函数 who()，是通过类（Base）的具体对象（b）来调用的，</span></span><br><span class="line"><span class="comment">// 编译期间就能确定了，所以它可以是内联的，</span></span><br><span class="line"><span class="comment">// 但最终是否内联取决于编译器。 </span></span><br><span class="line">Base b;</span><br><span class="line">b.who();</span><br><span class="line"></span><br><span class="line"><span class="comment">// 此处的虚函数是通过指针调用的，呈现多态性，</span></span><br><span class="line"><span class="comment">// 需要在运行时期间才能确定，所以不能为内联。  </span></span><br><span class="line">Base *ptr = <span class="keyword">new</span> Derived();</span><br><span class="line">ptr-&gt;who();</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
<li><p>虚函数指针、虚函数表</p>
<ul>
<li>虚函数指针：在含有虚函数类的对象中，指向虚函数表，在运行时确定。</li>
<li>虚函数表：在程序内存的<code>只读数据段</code>（.rodata section，见：<a href="#CPP目标文件内存布局">CPP目标文件内存布局</a>），存放虚函数指针，如果派生类实现了基类的某个虚函数，则在虚表中覆盖原本基类的那个虚函数指针，在编译时根据类的声明创建。</li>
<li>virtual修饰符:<br>  如果一个类是局部变量则该类数据存储在栈区，如果一个类是通过new/malloc动态申请的，则该类数据存储在堆区。<br>  如果该类是virutal继承而来的子类，则该类的虚函数表指针和该类其他成员一起存储。虚函数表指针指向只读数据段中的类虚函数表，虚函数表中存放着一个个函数指针，函数指针指向代码段中的具体函数。</li>
<li><img src="/img/noodle_plan/cpp/virtual_func_1.jpg" alt></li>
</ul>
</li>
<li><p>内存泄漏的工具 vargrid..? 还有啥工具</p>
</li>
<li>了解ASAN查找内存越界问题 </li>
<li>cpp找找冰川, 大梦龙图的面试题，网上常用题</li>
<li>gdb怎么切换线程</li>
<li>C++ 的动态多态怎么实现的？</li>
<li>C++ 的构造函数可以是虚函数吗？</li>
<li>无锁队列原理是否一定比有锁快?(不一定, 如果临界区小因为有上下文切换则mutex慢, 再来看lockfree的spin，一般都遵循一个固定的格式：先把一个不变的值X存到某个局部变量A里，然后做一些计算，计算/生成一个新的对象，然后做一个CAS操作，判断A和X还是不是相等的，如果是，那么这次CAS就算成功了，否则再来一遍。如果上面这个loop里面“计算/生成一个新的对象”非常耗时并且contention很严重，那么lockfree性能有时会比mutex差。另外lockfree不断地spin引起的CPU同步cacheline的开销也比mutex版本的大。关于ABA问题)</li>
</ul>
<h2 id="编译过程"><a href="#编译过程" class="headerlink" title="编译过程"></a>编译过程</h2><img src="http://www.plantuml.com/plantuml/svg/YzQALT3LjLF8ICt9oTTBveg6yejBKZBpzJAueE8AkaMPwHabG8cNYrgUBcbvFg6D2we4h1mX2cSXj43Co5JWWZ7WCi_tJ7knVY8NX4BNa0XLduYGUBQn7QYM2qAXgy-7gi-7k6ZolcTzIxboCfEIGIOWH20KGdEYNdvf2G00">
<ol>
<li>预处理(Preprocessing): 做一些类似于将所有的<code>#define</code>删除，并且展开所有的宏定义的操作, 然后生成hello.i</li>
<li>编译(Compilation): 编译过程就是把预处理完的文件进行一系列的词法分析，语法分析，语义分析及优化后生成相应的汇编代码。得到hello.a</li>
<li>汇编(Assembly): 汇编器是将汇编代码转变成机器可以执行的命令，每一个汇编语句几乎都对应一条机器指令。汇编相对于编译过程比较简单，根据汇编指令和机器指令的对照表一一翻译即可。得到hello.o</li>
<li>链接(Linking): 通过调用链接器ld来链接程序运行需要的一大堆目标文件，以及所依赖的其它库文件，最后生成可执行文件<ul>
<li>静态链接: 指在编译阶段直接把静态库加入到可执行文件中去，这样可执行文件会比较大</li>
<li>动态链接: 指链接阶段仅仅只加入一些描述信息，而程序执行时再从系统中把相应动态库加载到内存中去。</li>
</ul>
</li>
</ol>
<h2 id="目标文件"><a href="#目标文件" class="headerlink" title="目标文件"></a>目标文件</h2><p>编译器编译源代码后生成的文件叫做目标文件。目标文件从结构上讲，它是已经编译后的可执行文件格式，只是还没有经过链接的过程，其中可能有些符号或有些地址还没有被调整。</p>
<blockquote>
<p>可执行文件（Windows 的 <code>.exe</code> 和 Linux 的 <code>ELF</code>）、动态链接库（Windows 的 <code>.dll</code> 和 Linux 的 <code>.so</code>）、静态链接库（Windows 的 <code>.lib</code> 和 Linux 的 <code>.a</code>）都是按照可执行文件格式存储（Windows 按照 PE-COFF，Linux 按照 ELF）</p>
</blockquote>
<p>目标文件格式:  </p>
<ul>
<li>Windows 的 PE（Portable Executable），或称为 PE-COFF，<code>.obj</code> 格式</li>
<li>Linux 的 ELF（Executable Linkable Format），<code>.o</code> 格式</li>
<li>Intel/Microsoft 的 OMF（Object Module Format）</li>
<li>Unix 的 <code>a.out</code> 格式</li>
<li>MS-DOS 的 <code>.COM</code> 格式</li>
</ul>
<blockquote>
<p>PE 和 ELF 都是 COFF（Common File Format）的变种</p>
</blockquote>
<h3 id="CPP目标文件内存布局"><a href="#CPP目标文件内存布局" class="headerlink" title="CPP目标文件内存布局"></a>CPP目标文件内存布局</h3><table><thead><tr><th>段</th><th>功能</th></tr></thead><tbody><tr><td>File Header</td><td>文件头，描述整个文件的文件属性（包括文件是否可执行、是静态链接或动态连接及入口地址、目标硬件、目标操作系统等）</td></tr><tr><td>.text section</td><td>代码段，执行语句编译成的机器代码</td></tr><tr><td>.data section</td><td>数据段，已初始化的全局变量和局部静态变量</td></tr><tr><td>.bss section</td><td>BSS 段（Block Started by Symbol），未初始化的全局变量和局部静态变量（因为默认值为 0，所以只是在此预留位置，不占空间）</td></tr><tr><td>.rodata section</td><td>只读数据段，存放只读数据，一般是程序里面的只读变量（如 const 修饰的变量）和字符串常量</td></tr><tr><td>.comment section</td><td>注释信息段，存放编译器版本信息</td></tr><tr><td>.note.GNU-stack section</td><td>堆栈提示段</td></tr></tbody></table>


          
        
      


      

    
      <footer class="post-footer">
        

        

        

        
        
          <div class="post-eof"></div>
        
      </footer>
      
    </div>
    
    
    

    

    

    

  </div>
  
  
  
  </article>


      
    
      
        

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://hulinhong.com/2021/03/08/self_cultivation_linux_memory_manage/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="no5ix">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/uploads/avatar.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="烫">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2021/03/08/self_cultivation_linux_memory_manage/" itemprop="url">服务器开发自我修养专栏-Linux内存管理</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2021-03-08T19:08:06+00:00">
                2021-03-08
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Self-cultivation/" itemprop="url" rel="index">
                    <span itemprop="name">Self-cultivation</span>
                  </a>
                </span>

                
                
              
            </span>
          

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    




    
    
    
    <div class="post-body" itemprop="articleBody">
      
      

      

      
      
        <div class="post-eof"></div>
      

      
      

      
        
          
            <h1 id="Linux内存管理"><a href="#Linux内存管理" class="headerlink" title="Linux内存管理"></a>Linux内存管理</h1><h2 id="为什么需要虚拟内存"><a href="#为什么需要虚拟内存" class="headerlink" title="为什么需要虚拟内存"></a>为什么需要虚拟内存</h2><p>虚拟内存的目的是为了让物理内存扩充成更大的逻辑内存，从而让程序获得更多的可用内存。</p>
<p>为了更好的管理内存，操作系统将内存抽象成地址空间。每个程序拥有自己的地址空间，这个地址空间被分割成多个块，每一块称为一页。这些页被映射到物理内存，但不需要映射到连续的物理内存，也不需要所有页都必须在物理内存中。当程序引用到不在物理内存中的页时，由硬件执行必要的映射，将缺失的部分装入物理内存并重新执行失败的指令。</p>
<p>从上面的描述中可以看出，<strong>虚拟内存允许程序不用将地址空间中的每一页都映射到物理内存，也就是说一个程序不需要全部调入内存就可以运行，这使得有限的内存运行大程序成为可能。</strong>例如有一台计算机可以产生 16 位地址，那么一个程序的地址空间范围是 0~64K。该计算机只有 32KB 的物理内存，虚拟内存技术允许该计算机运行一个 64K 大小的程序。</p>
<h2 id="MMU工作原理"><a href="#MMU工作原理" class="headerlink" title="MMU工作原理"></a>MMU工作原理</h2><p>内存管理单元（MMU）管理着地址空间和物理内存的转换，其中的页表（Page table）存储着页（程序地址空间）和页框（物理内存空间）的映射表。</p>
<p>一个虚拟地址分成两个部分:  </p>
<ul>
<li>一部分存储页面号，</li>
<li>一部分存储偏移量。</li>
</ul>
<p><img src="/img/noodle_plan/linux/mmu_1.jpg" alt><br>上图的页表存放着 16 个页，这 16 个页需要用 4 个比特位来进行索引定位。例如对于虚拟地址（0010 000000000100），前 4 位是存储页面号 2，读取表项内容为（110 1），页表项最后一位表示是否存在于内存中，1 表示存在。后 12 位存储偏移量。这个页对应的页框的地址为 （110 000000000100）。</p>
<h2 id="主机字节序"><a href="#主机字节序" class="headerlink" title="主机字节序"></a>主机字节序</h2><p>主机字节序又叫 CPU 字节序，其不是由操作系统决定的，而是由 CPU 指令集架构决定的。主机字节序分为两种：  </p>
<ul>
<li><strong>记忆技巧</strong>: 低序地址存了高序字节就叫大端, 反之就小端</li>
<li>大端字节序（Big Endian）：高序字节存储在低位地址，低序字节存储在高位地址, 目前主要是ARM/PowerPC在用</li>
<li>小端字节序（Little Endian）：低序字节存储在低位地址, 高序字节存储在高位地址，目前主要是Intel在用</li>
</ul>
<p>存储方式:<br>32 位整数 0x12345678 是从起始位置为 0x00 的地址开始存放，则：</p>
<table>
<thead>
<tr>
<th style="text-align:center">内存地址</th>
<th style="text-align:center">0x00</th>
<th style="text-align:center">0x01</th>
<th style="text-align:center">0x02</th>
<th style="text-align:center">0x03</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">大端</td>
<td style="text-align:center">12</td>
<td style="text-align:center">34</td>
<td style="text-align:center">56</td>
<td style="text-align:center">78</td>
</tr>
<tr>
<td style="text-align:center">小端</td>
<td style="text-align:center">78</td>
<td style="text-align:center">56</td>
<td style="text-align:center">34</td>
<td style="text-align:center">12</td>
</tr>
</tbody>
</table>
<h2 id="网络字节序"><a href="#网络字节序" class="headerlink" title="网络字节序"></a>网络字节序</h2><p>网络字节顺序是 TCP/IP 中规定好的一种数据表示格式，它与具体的 CPU 类型、操作系统等无关，从而可以保证数据在不同主机之间传输时能够被正确解释。</p>
<p>网络字节顺序采用：大端（Big Endian）排列方式。</p>
<h2 id="Linux虚拟地址空间如何分布"><a href="#Linux虚拟地址空间如何分布" class="headerlink" title="Linux虚拟地址空间如何分布"></a>Linux虚拟地址空间如何分布</h2><p>Linux 使用虚拟地址空间，大大增加了进程的寻址空间，由低地址到高地址(下图中从下到上即为从低到高)分别为(口诀: 文初堆栈)：</p>
<p><img src="/img/noodle_plan/linux/virtual_memory_mgr.jpeg" alt></p>
<ul>
<li>文本段(只读段)：该部分空间只能读，不可写；(包括：代码段、rodata 段(C常量字符串和#define定义的常量) )</li>
<li>数据段(初始化数据段与未初始化数据段)：保存初始化了的与未初始化的全局变量、静态变量的空间；</li>
<li>堆 ：就是平时所说的动态内存， malloc/new 大部分都来源于此。其中堆顶的位置可通过函数 brk 和 sbrk 进行动态调整。</li>
<li>文件映射区域 ：如动态库、共享内存等映射物理空间的内存，一般是 mmap 函数所分配的虚拟地址空间。</li>
<li>栈：用于维护函数调用的上下文空间，一般为 8M ，可通过 ulimit –s 查看。</li>
<li>内核虚拟空间：用户代码不可见的内存区域，由内核管理(页表就存放在内核虚拟空间)。上图是 32 位系统典型的虚拟地址空间分布(来自《深入理解计算机系统》)。</li>
</ul>
<h2 id="brk函数"><a href="#brk函数" class="headerlink" title="brk函数"></a>brk函数</h2><p>先了解：brk()和sbrk()函数<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">brk</span><span class="params">( <span class="keyword">const</span> <span class="keyword">void</span> *addr )</span></span></span><br><span class="line"><span class="function"><span class="keyword">void</span>* <span class="title">sbrk</span> <span class="params">( <span class="keyword">intptr_t</span> incr )</span></span>;</span><br></pre></td></tr></table></figure></p>
<p>这两个函数的作用主要是扩展heap的上界brk。第一个函数的参数为设置的新的brk上界地址，如果成功返回0，失败返回-1。第二个函数的参数为需要申请的内存的大小，然后返回heap新的上界brk地址。如果sbrk的参数为0，则返回的为原来的brk地址。</p>
<h2 id="mmap"><a href="#mmap" class="headerlink" title="mmap"></a>mmap</h2><p>虚拟内存系统通过将虚拟内存分割为称作虚拟页 (Virtual Page，VP) 大小固定的块，一般情况下，每个虚拟页的大小默认是 4096 字节。同样的，物理内存也被分割为物理页(Physical Page，PP)，也为 4096 字节。</p>
<p>在 LINUX 中我们可以使用 mmap 用来在进程虚拟内存地址空间中分配地址空间，创建和物理内存的映射关系。</p>
<p><img src="/img/noodle_plan/linux/mmap.jpg" alt="映射关系"></p>
<p><strong>映射关系可以分为两种</strong>  </p>
<ol>
<li>文件映射<br> 磁盘文件映射进程的虚拟地址空间，使用文件内容初始化物理内存。  </li>
<li>匿名映射<br> 初始化全为 0 的内存空间。</li>
</ol>
<p><strong>而对于映射关系是否共享又分为</strong>  </p>
<ol>
<li>私有映射 (MAP_PRIVATE)<br> 多进程间数据共享，修改不反应到磁盘实际文件，是一个 copy-on-write（写时复制）的映射方式。  </li>
<li>共享映射 (MAP_SHARED)<br> 多进程间数据共享，修改反应到磁盘实际文件中。</li>
</ol>
<p><strong>因此总结起来有 4 种组合</strong>  </p>
<ol>
<li>私有文件映射<br> 多个进程使用同样的物理内存页进行初始化，但是各个进程对内存文件的修改不会共享，也不会反应到物理文件中</li>
<li>私有匿名映射<br> mmap 会创建一个新的映射，各个进程不共享，这种使用主要用于分配内存 (malloc 分配大内存会调用 mmap)。<br> 例如开辟新进程时，会为每个进程分配虚拟的地址空间，这些虚拟地址映射的物理内存空间各个进程间读的时候共享，写的时候会 copy-on-write。</li>
<li>共享文件映射<br> 多个进程通过虚拟内存技术共享同样的物理内存空间，对内存文件 的修改会反应到实际物理文件中，他也是进程间通信 (IPC) 的一种机制。</li>
<li>共享匿名映射<br> 这种机制在进行 fork 的时候不会采用写时复制，父子进程完全共享同样的物理内存页，这也就实现了父子进程通信 (IPC).</li>
</ol>
<p><strong>这里值得注意的是，mmap 只是在虚拟内存分配了地址空间，只有在第一次访问虚拟内存的时候才分配物理内存。</strong><br>在 mmap 之后，并没有在将文件内容加载到物理页上，只上在虚拟内存中分配了地址空间。当进程在访问这段地址时，通过查找页表，发现虚拟内存对应的页没有在物理内存中缓存，则产生 “缺页”，由内核的缺页异常处理程序处理，将文件对应内容，以页为单位 (4096) 加载到物理内存，注意是只加载缺页，但也会受操作系统一些调度策略影响，加载的比所需的多。</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> *<span class="title">mmap</span><span class="params">(<span class="keyword">void</span> *addr, <span class="keyword">size_t</span> length, <span class="keyword">int</span> prot, <span class="keyword">int</span> flags, <span class="keyword">int</span> fd, <span class="keyword">off_t</span> offset)</span></span>;</span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">munmap</span><span class="params">(<span class="keyword">void</span> *addr, <span class="keyword">size_t</span> length)</span></span>;</span><br></pre></td></tr></table></figure>
<p>这里要注意的是fd参数，fd为映射的文件描述符，如果是匿名映射，可以设为-1；</p>
<ul>
<li>mmap函数第一种用法是映射磁盘文件到内存中；而malloc使用的是mmap函数的第二种用法，即匿名映射，匿名映射不映射磁盘文件，而是向映射区申请一块内存。</li>
<li>munmap函数是用于释放内存，第一个参数为内存首地址，第二个参数为内存的长度。接下来看下mmap函数的参数。</li>
</ul>
<p>由于brk/sbrk/mmap属于系统调用，如果每次申请内存，都调用这三个函数中的一个，那么每次都要产生系统调用开销（即cpu从用户态切换到内核态的上下文切换，这里要保存用户态数据，等会还要切换回用户态），这是非常影响性能的；其次，这样申请的内存容易产生碎片，因为堆是从低地址到高地址，如果低地址的内存没有被释放，高地址的内存就不能被回收。</p>
<h2 id="malloc和free原理"><a href="#malloc和free原理" class="headerlink" title="malloc和free原理"></a>malloc和free原理</h2><p>malloc: </p>
<ul>
<li><strong>当申请小内存的时，malloc使用sbrk分配内存</strong></li>
<li><strong>当申请大内存时，使用mmap函数申请内存</strong></li>
<li><strong>但是这只是分配了虚拟内存，还没有映射到物理内存，当访问申请的内存时，才会因为缺页异常，内核分配物理内存。</strong></li>
<li>将所有空闲内存块连成链表，每个节点记录空闲内存块的地址、大小等信息</li>
<li>分配内存时，找到大小合适的块，切成两份，一分给用户，一份放回空闲链表</li>
<li>free时，直接把内存块返回链表</li>
<li>解决外部碎片：将能够合并的内存块进行合并</li>
</ul>
<p>malloc函数的实质体现在：它有一个将可用的内存块连接为一个长长的列表的所谓空闲链表。调用malloc函数时，它沿连接表寻找一个大到足以满足用户请求所需要的内存块。然后，将该内存块一分为二（一块的大小与用户请求的大小相等，另一块的大小就是剩下的字节）。接下来，将分配给用户的那块内存传给用户，并将剩下的那块（如果有的话）返回到连接表上。</p>
<p>这里注意，malloc找到的内存块大小一定是会大于等于我们需要的内存大小，下面会提到如果所有的内存块都比要求的小会怎么办？</p>
<p><strong>调用free函数时，它将用户释放的内存块连接到空闲链上。到最后，空闲链会被切成很多的小内存片段，如果这时用户申请一个大的内存片段，那么空闲链上可能没有可以满足用户要求的片段了。于是，malloc函数请求延时，并开始在空闲链上翻箱倒柜地检查各内存片段，对它们进行整理，将相邻的小空闲块合并成较大的内存块。</strong></p>
<p>在对内存块进行了 free 调用之后，我们需要做的是诸如将它们标记为未被使用的等事情，并且，在调用 malloc 时，我们要能够定位未被使用的内存块。因此， malloc返回的每块内存的起始处首先要有这个结构：</p>
<p>这就解释了，为什么在程序中free之后，但是堆的内存还是没有释放。</p>
<p>内存控制块结构定义<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">mem_control_block</span> &#123;</span></span><br><span class="line">    <span class="keyword">int</span> is_available;</span><br><span class="line">    <span class="keyword">int</span> size;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure></p>
<p>现在，您可能会认为当程序调用 malloc 时这会引发问题 —— 它们如何知道这个结构？答案是它们不必知道；在返回指针之前，我们会将其移动到这个结构之后，把它隐藏起来。这使得返回的指针指向没有用于任何其他用途的内存。那样，从调用程序的角度来看，它们所得到的全部是空闲的、开放的内存。然后，当通过 free() 将该指针传递回来时，我们只需要倒退几个内存字节就可以再次找到这个结构。</p>
<p><strong>关于 malloc 获得虚存空间的实现，与 glibc 的版本有关，但大体逻辑是：</strong></p>
<ul>
<li>若分配内存小于 128k ，调用 sbrk() ，将堆顶指针向高地址移动，获得新的虚存空间。</li>
<li>若分配内存大于 128k ，调用 mmap() ，在文件映射区域中分配匿名虚存空间。</li>
</ul>
<p>接着： VSZ为虚拟内存 RSS为物理内存</p>
<ul>
<li>VSZ 并不是每次 malloc 后都增长，是与上一节说的堆顶没发生变化有关，因为可重用堆顶内剩余的空间，这样的 malloc 是很轻量快速的。</li>
<li>但如果 VSZ 发生变化，基本与分配内存量相当，因为 VSZ 是计算虚拟地址空间总大小。</li>
<li>RSS 的增量很少，是因为 malloc 分配的内存并不就马上分配实际存储空间，只有第一次使用，如第一次 memset 后才会分配。</li>
<li>由于每个物理内存页面大小是 4k ，不管 memset 其中的 1k 还是 5k 、 7k ，实际占用物理内存总是 4k 的倍数。所以 RSS 的增量总是 4k 的倍数。</li>
<li>因此，不是 malloc 后就马上占用实际内存，而是第一次使用时发现虚存对应的物理页面未分配，产生缺页中断，才真正分配物理页面，同时更新进程页面的映射关系。这也是 Linux 虚拟内存管理的核心概念之一。</li>
</ul>
<h2 id="vmalloc和kmalloc和malloc的区别"><a href="#vmalloc和kmalloc和malloc的区别" class="headerlink" title="vmalloc和kmalloc和malloc的区别"></a>vmalloc和kmalloc和malloc的区别</h2><ul>
<li>kmalloc和vmalloc是分配的是内核的内存,malloc分配的是用户的内存</li>
<li>kmalloc保证分配的内存在物理上是连续的,vmalloc保证的是在虚拟地址空间上的连续,malloc不保证任何东西(这点是自己猜测的,不一定正确)</li>
<li>kmalloc能分配的大小有限,vmalloc和malloc能分配的大小相对较大</li>
<li>内存只有在要被DMA访问的时候才需要物理上连续</li>
<li>vmalloc比kmalloc要慢</li>
</ul>
<p><img src="/img/noodle_plan/linux/virtual_memory_mgr1.jpg" alt></p>
<p>对于提供了MMU（存储管理器，辅助操作系统进行内存管理，提供虚实地址转换等硬件支持）的处理器而言，Linux提供了复杂的存储管理系统，使得进程所能访问的内存达到4GB。</p>
<p>进程的4GB内存空间被人为的分为两个部分–用户空间与内核空间。用户空间地址分布从0到3GB(PAGE_OFFSET，在0x86中它等于0xC0000000)，3GB到4GB为内核空间。</p>
<p>内核空间中，从3G到vmalloc_start这段地址是物理内存映射区域（该区域中包含了内核镜像、物理页框表mem_map等等），比如我们使用 的 VMware虚拟系统内存是160M，那么3G～3G+160M这片内存就应该映射物理内存。在物理内存映射区之后，就是vmalloc区域。对于 160M的系统而言，vmalloc_start位置应在3G+160M附近（在物理内存映射区与vmalloc_start期间还存在一个8M的gap 来防止跃界），vmalloc_end的位置接近4G(最后位置系统会保留一片128k大小的区域用于专用页面映射)</p>
<p>一般情况下，只有硬件设备才需要物理地址连续的内存，因为硬件设备往往存在于MMU之外，根本不了解虚拟地址；但为了性能上的考虑，内核中一般使用kmalloc(),而只有在需要获得大块内存时才使用vmalloc，例如当模块被动态加载到内核当中时，就把模块装载到由vmalloc（）分配的内存上。</p>
<ul>
<li><strong>kmalloc</strong>:<br>  kmalloc申请的是较小的连续的物理内存，内存物理地址上连续，虚拟地址上也是连续的，使用的是内存分配器slab的一小片。申请的内存位于物理内存的映射区域。其真正的物理地址只相差一个固定的偏移。而且不对获得空间清零。可以查看<a href="#Slab分配器">slab分配器</a></li>
<li><strong>kzalloc</strong>:<br>  用kzalloc申请内存的时候， 效果等同于先是用 kmalloc() 申请空间 , 然后用 memset() 来初始化 ,所有申请的元素都被初始化为 0.</li>
<li><strong>vmalloc</strong>:<br>  vmalloc用于申请较大的内存空间，虚拟内存是连续。申请的内存的则位于vmalloc_start～vmalloc_end之间，与物理地址没有简单的转换关系，虽然在逻辑上它们也是连续的，但是在物理上它们不要求连续。</li>
<li><strong>malloc</strong>:<br>  malloc分配的是用户的内存。除非被阻塞否则他执行的速度非常快，而且不对获得空间清零。</li>
</ul>
<h2 id="Buddy（伙伴）分配算法"><a href="#Buddy（伙伴）分配算法" class="headerlink" title="Buddy（伙伴）分配算法"></a>Buddy（伙伴）分配算法</h2><p>参考: <a href="https://zhuanlan.zhihu.com/p/149581303" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/149581303</a></p>
<p>伙伴系统用于管理物理页，主要目的在于维护可用的连续物理空间，避免外部碎片。所有关于内存分配的操作都会与其打交道，buddy是物理内存的管理的门户</p>
<p>Linux 内核引入了伙伴系统算法（Buddy system），什么意思呢？就是把相同大小的页框块用链表串起来，页框块就像手拉手的好伙伴，也是这个算法名字的由来。</p>
<p>具体的，所有的空闲页框分组为11个块链表，每个块链表分别包含大小为1，2，4，8，16，32，64，128，256，512和1024个连续页框的页框块。最大可以申请1024个连续页框，对应4MB大小的连续内存。</p>
<p><img src="/img/noodle_plan/linux/buddy_algo.jpg" alt></p>
<p>伙伴系统:<br>因为任何正整数都可以由 2^n 的和组成，所以总能找到合适大小的内存块分配出去，减少了外部碎片产生 。</p>
<p>分配实例:<br>比如：我需要申请4个页框，但是长度为4个连续页框块链表没有空闲的页框块，伙伴系统会从连续8个页框块的链表获取一个，并将其拆分为两个连续4个页框块，取其中一个，另外一个放入连续4个页框块的空闲链表中。释放的时候会检查，释放的这几个页框前后的页框是否空闲，能否组成下一级长度的块。</p>
<h2 id="Slab分配器"><a href="#Slab分配器" class="headerlink" title="Slab分配器"></a>Slab分配器</h2><p>伙伴系统和slab不是二选一的关系，slab 内存分配器是对伙伴分配算法的补充</p>
<p>slab的目的在于避免内部碎片。从buddy系统获取的内存至少是一个页，也就是4K，如果仅仅需要8字节的内存，显然巨大的内部碎片无法容忍。</p>
<p><strong>slab从buddy系统申请空间，将较大的连续内存拆分成一系列较小的内存块。</strong></p>
<p>用户申请空间时从slab中获取大小最相近的小块内存，这样可以有效减少内部碎片。在slab最大的块为8K，slab中所有块在物理上也是连续的。</p>
<p>上面说的用于内存分配的slab是通用的slab，主要用于支持kmalloc分配内存。</p>
<p>slab还有一个作用就是用作对象池，针对经常分配和回收的对象比如task_struct，可以分配一个slab对象池对其优化。这种slab是独立于通用的内存分配slab的，在内核中有很多这样的针对特定对象的slab。</p>
<p><strong>在内核中想要分配一段连续的内存</strong>，首先向slab系统申请，如果不满足（超过两个页面，也就是8K），直接向buddy系统申请。如果还不满足（超过4M，也就是1024个页面），将无法获取到连续的物理地址。可以通过vmalloc获取虚拟地址空间连续，但物理地址不连续的更大的内存空间。</p>
<p><img src="/img/noodle_plan/linux/buddy_algo2.png" alt></p>
<p>malloc是用户态使用的内存分配接口，最终还是向buddy申请内存，因为buddy系统是管理物理内存的门户。申请到大块内存后，再像slab一样对其进行细分维护，根据用户需要返回相应内存的指针。</p>
<h2 id="fork内存语义"><a href="#fork内存语义" class="headerlink" title="fork内存语义"></a>fork内存语义</h2><ul>
<li>共享代码段, 子指向父 : 父子进程共享同一代码段, 子进程的页表项指向父进程相同的物理内存页(即数据段/堆段/栈段的各页)</li>
<li>写时复制(copy-on-write) : 内核会捕获所有父进程或子进程针对这些页面(即数据段/堆段/栈段的各页)的修改企图, 并为将要修改的页面创建拷贝, 将新的页面拷贝分配给遭内核捕获的进程, 从此父/子进程可以分别修改各自的页拷贝, 不再相互影响.</li>
</ul>
<p>虽然fork创建的子进程不需要拷贝父进程的物理内存空间, 但是会复制父进程的空间内存页表. 例如对于10GB的redis进程, 需要复制约20MB的内存页表, 因为此fork操作耗时跟进程总内存量息息相关</p>
<h2 id="零拷贝"><a href="#零拷贝" class="headerlink" title="零拷贝"></a>零拷贝</h2><p>参考 <a href="https://juejin.im/post/6844903949359644680" target="_blank" rel="noopener">https://juejin.im/post/6844903949359644680</a></p>
<p>“先从简单开始，实现下这个场景：从一个文件中读出数据并将数据传到另一台服务器上？”<br>大概伪代码如下:<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">File.read(file, buf, len);</span><br><span class="line">Socket.send(socket, buf, len);</span><br></pre></td></tr></table></figure></p>
<p>可以看出, 这样效率是很低的. </p>
<p>下图分别对应传统 I/O 操作的数据读写流程，整个过程涉及 2 次 CPU 拷贝、2 次 DMA 拷贝总共 4 次拷贝，以及 4 次上下文切换，下面简单地阐述一下相关的概念。<br><img src="/img/noodle_plan/linux/traditional_io.jpg" alt></p>
<ul>
<li>上下文切换：当用户程序向内核发起系统调用时，CPU 将用户进程从用户态切换到内核态；当系统调用返回时，CPU 将用户进程从内核态切换回用户态。</li>
<li>CPU拷贝：由 CPU 直接处理数据的传送，数据拷贝时会一直占用 CPU 的资源。</li>
<li>DMA拷贝：由 CPU 向DMA磁盘控制器下达指令，让 DMA 控制器来处理数据的传送，数据传送完毕再把信息反馈给 CPU，从而减轻了 CPU 资源的占有率。</li>
</ul>
<h3 id="传统读操作"><a href="#传统读操作" class="headerlink" title="传统读操作"></a>传统读操作</h3><p>当应用程序执行 read 系统调用读取一块数据的时候，如果这块数据已经存在于用户进程的页内存中，就直接从内存中读取数据；如果数据不存在，则先将数据从磁盘加载数据到内核空间的读缓存（read buffer）中，再从读缓存拷贝到用户进程的页内存中。<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">read(file_fd, tmp_buf, len);</span><br></pre></td></tr></table></figure></p>
<p>复制代码基于传统的 I/O 读取方式，read 系统调用会触发 2 次上下文切换，1 次 DMA 拷贝和 1 次 CPU 拷贝，发起数据读取的流程如下：</p>
<ol>
<li>用户进程通过 read() 函数向内核（kernel）发起系统调用，上下文从用户态（user space）切换为内核态（kernel space）。</li>
<li>CPU利用DMA控制器将数据从主存或硬盘拷贝到内核空间（kernel space）的读缓冲区（read buffer）。</li>
<li>CPU将读缓冲区（read buffer）中的数据拷贝到用户空间（user space）的用户缓冲区（user buffer）。</li>
<li>上下文从内核态（kernel space）切换回用户态（user space），read 调用执行返回。</li>
</ol>
<h3 id="传统写操作"><a href="#传统写操作" class="headerlink" title="传统写操作"></a>传统写操作</h3><p>当应用程序准备好数据，执行 write 系统调用发送网络数据时，先将数据从用户空间的页缓存拷贝到内核空间的网络缓冲区（socket buffer）中，然后再将写缓存中的数据拷贝到网卡设备完成数据发送。<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">write(socket_fd, tmp_buf, len);</span><br></pre></td></tr></table></figure></p>
<p>复制代码基于传统的 I/O 写入方式，write() 系统调用会触发 2 次上下文切换，1 次 CPU 拷贝和 1 次 DMA 拷贝，用户程序发送网络数据的流程如下：</p>
<ol>
<li>用户进程通过 write() 函数向内核（kernel）发起系统调用，上下文从用户态（user space）切换为内核态（kernel space）。</li>
<li>CPU 将用户缓冲区（user buffer）中的数据拷贝到内核空间（kernel space）的网络缓冲区（socket buffer）。</li>
<li>CPU 利用 DMA 控制器将数据从网络缓冲区（socket buffer）拷贝到网卡进行数据传输。</li>
<li>上下文从内核态（kernel space）切换回用户态（user space），write 系统调用执行返回。</li>
</ol>
<h3 id="sendfile"><a href="#sendfile" class="headerlink" title="sendfile"></a>sendfile</h3><p>sendfile 系统调用在 Linux 内核版本 2.1 中被引入，目的是简化通过网络在两个通道之间进行的数据传输过程。sendfile 系统调用的引入，不仅减少了 CPU 拷贝的次数，还减少了上下文切换的次数，它的伪代码如下：<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sendfile(socket_fd, file_fd, len);</span><br></pre></td></tr></table></figure></p>
<p>复制代码通过 sendfile 系统调用，数据可以直接在内核空间内部进行 I/O 传输，从而省去了数据在用户空间和内核空间之间的来回拷贝。与 mmap 内存映射方式不同的是， sendfile 调用中 I/O 数据对用户空间是完全不可见的。也就是说，这是一次完全意义上的数据传输过程。</p>
<p><img src="/img/noodle_plan/linux/sendfile1.jpg" alt></p>
<p>基于 sendfile 系统调用的零拷贝方式，整个拷贝过程会发生 2 次上下文切换，1 次 CPU 拷贝和 2 次 DMA 拷贝，用户程序读写数据的流程如下：</p>
<ol>
<li>用户进程通过 sendfile() 函数向内核（kernel）发起系统调用，上下文从用户态（user space）切换为内核态（kernel space）。</li>
<li>CPU 利用 DMA 控制器将数据从主存或硬盘拷贝到内核空间（kernel space）的读缓冲区（read buffer）。</li>
<li>CPU 将读缓冲区（read buffer）中的数据拷贝到的网络缓冲区（socket buffer）。</li>
<li>CPU 利用 DMA 控制器将数据从网络缓冲区（socket buffer）拷贝到网卡进行数据传输。</li>
<li>上下文从内核态（kernel space）切换回用户态（user space），sendfile 系统调用执行返回。</li>
</ol>
<p>相比较于 mmap 内存映射的方式，sendfile 少了 2 次上下文切换，但是仍然有 1 次 CPU 拷贝操作。sendfile 存在的问题是用户程序不能对数据进行修改，而只是单纯地完成了一次数据传输过程。</p>
<p>“这样确实改善了很多，但还没达到零拷贝的要求（还有一次cpu参与的拷贝），还有其它黑技术？”<br>“对的，如果底层网络接口卡支持收集(gather)操作的话，就可以进一步的优化。”<br>“怎么说？”<br>“继续看下一小节”  </p>
<h3 id="sendfile-DMA-gather-copy"><a href="#sendfile-DMA-gather-copy" class="headerlink" title="sendfile + DMA gather copy"></a>sendfile + DMA gather copy</h3><p>Linux 2.4 版本的内核对 sendfile 系统调用进行修改，如果底层网络接口卡支持收集(gather)操作的话, 为  DMA 拷贝引入了 gather 操作。它将内核空间（kernel space）的读缓冲区（read buffer）中对应的数据描述信息（内存地址、地址偏移量）记录到相应的网络缓冲区（ socket  buffer）中，由 DMA 根据内存地址、地址偏移量将数据批量地从读缓冲区（read buffer）拷贝到网卡设备中，这样就省去了内核空间中仅剩的 1 次 CPU 拷贝操作，sendfile 的伪代码如下：<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sendfile(socket_fd, file_fd, len);</span><br></pre></td></tr></table></figure></p>
<p>复制代码在硬件的支持下，sendfile 拷贝方式不再从内核缓冲区的数据拷贝到 socket 缓冲区，取而代之的仅仅是缓冲区文件描述符和数据长度的拷贝，这样 DMA 引擎直接利用 gather 操作将页缓存中数据打包发送到网络中即可，本质就是和虚拟内存映射的思路类似。</p>
<p><img src="/img/noodle_plan/linux/sendfile2.jpg" alt></p>
<p>基于 sendfile + DMA gather copy 系统调用的零拷贝方式，整个拷贝过程会发生 2 次上下文切换、0 次 CPU 拷贝以及 2 次 DMA 拷贝，用户程序读写数据的流程如下：</p>
<ol>
<li>用户进程通过 sendfile() 函数向内核（kernel）发起系统调用，上下文从用户态（user space）切换为内核态（kernel space）。</li>
<li>CPU 利用 DMA 控制器将数据从主存或硬盘拷贝到内核空间（kernel space）的读缓冲区（read buffer）。</li>
<li>CPU 把读缓冲区（read buffer）的文件描述符（file descriptor）和数据长度拷贝到网络缓冲区（socket buffer）。</li>
<li>基于已拷贝的文件描述符（file descriptor）和数据长度，CPU 利用 DMA 控制器的 gather/scatter 操作直接批量地将数据从内核的读缓冲区（read buffer）拷贝到网卡进行数据传输。</li>
<li>上下文从内核态（kernel space）切换回用户态（user space），sendfile 系统调用执行返回。</li>
</ol>
<p>sendfile + DMA gather copy 拷贝方式同样存在用户程序不能对数据进行修改的问题，而且本身需要硬件的支持，它只适用于将数据从文件拷贝到 socket 套接字上的传输过程。</p>

          
        
      


      

    
      <footer class="post-footer">
        

        

        

        
        
          <div class="post-eof"></div>
        
      </footer>
      
    </div>
    
    
    

    

    

    

  </div>
  
  
  
  </article>


      
    
      
        

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://hulinhong.com/2021/03/08/self_cultivation_linux_process/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="no5ix">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/uploads/avatar.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="烫">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2021/03/08/self_cultivation_linux_process/" itemprop="url">服务器开发自我修养专栏-Linux进程管理</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2021-03-08T19:08:06+00:00">
                2021-03-08
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Self-cultivation/" itemprop="url" rel="index">
                    <span itemprop="name">Self-cultivation</span>
                  </a>
                </span>

                
                
              
            </span>
          

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    




    
    
    
    <div class="post-body" itemprop="articleBody">
      
      

      

      
      
        <div class="post-eof"></div>
      

      
      

      
        
          
            <h1 id="Linux进程管理"><a href="#Linux进程管理" class="headerlink" title="Linux进程管理"></a>Linux进程管理</h1><h2 id="读者-写者问题"><a href="#读者-写者问题" class="headerlink" title="读者-写者问题"></a>读者-写者问题</h2><p>定义： 允许多个进程同时对数据进行读操作，但是不允许读和写以及写和写操作同时发生。</p>
<p>解决方案：  </p>
<ul>
<li>读者优先<br>  读进程只要看到有其他读进程正在访问文件，就可以继续作读访问；写进程必须等待所有读进程都不访问时才能写文件，即使写进程可能比一些读进程更早提出申请。</li>
<li>读者写者公平竞争，老实排队<br>  因为读者优先的方案如果在读访问非常频繁的场合，有可能造成写进程一直无法访问文件的局面….为了避免这种情况的产生，读者写者请求都老实排队， 排到谁就执行谁， 不准读者插队</li>
<li>写者优先<br>  如果有写者申请写文件，那么在申请之前已经开始读取文件的可以继续读取，但是如果再有读者申请读取文件，则不能够读取，只有在所有的写者写完之后才可以读取</li>
</ul>
<h2 id="哲学家就餐问题"><a href="#哲学家就餐问题" class="headerlink" title="哲学家就餐问题"></a>哲学家就餐问题</h2><p><img src="/img/noodle_plan/linux/an_illustration_of_the_dining_philosophers_problem.png" alt></p>
<p>5 个沉默寡言的哲学家围坐在圆桌前，每人面前一盘意面。叉子放在哲学家之间的桌面上。（5 个哲学家，5 根叉子）</p>
<p>所有的哲学家都只会在思考和进餐两种行为间交替。哲学家只有同时拿到左边和右边的叉子才能吃到面，而同一根叉子在同一时间只能被一个哲学家使用。每个哲学家吃完面后都需要把叉子放回桌面以供其他哲学家吃面。只要条件允许，哲学家可以拿起左边或者右边的叉子，但在没有同时拿到左右叉子时不能进食。</p>
<p>设计一个进餐规则（并行算法）使得每个哲学家都不会挨饿；也就是说，在没有人知道别人什么时候想吃东西或思考的情况下，每个哲学家都可以在吃饭和思考之间一直交替下去。</p>
<p>显而易见，<strong>如果不小心处理会有死锁现象</strong>， 比如：当每个科学家都同时拿起了左边的筷子时候死锁发生了，都想拿自己右边的筷子，但是科学家每个人左手都不松手。导致都吃不了饭</p>
<p><a href="https://zhuanlan.zhihu.com/p/34553097" target="_blank" rel="noopener">参考</a><br>解决方案：  </p>
<ul>
<li>规定奇数号科学家先拿左边的筷子，然后拿右边的筷子。偶数号科学家先拿右边的筷子，然后那左边的筷子。导致0，1科学家竞争1号筷子，2，3科学家竞争3号筷子。四号科学家无人竞争。最后总有一个科学家能获得两只筷子。</li>
<li>仅当科学家左右两只筷子都能用的时候，才允许他进餐，代码里的用trylock来实现</li>
<li>至多允许四个哲学家同时去拿左边的筷子，最终保证至少有一个科学家能进餐，并且用完之后释放筷子，从而使更多的哲学家能够拿到筷子。</li>
</ul>
<h2 id="活锁"><a href="#活锁" class="headerlink" title="活锁"></a>活锁</h2><p>在某种情形下，轮询（忙等待）可用于进入临界区或存取资源。采用这一策略的主要原因是，相比所做的工作而言，互斥的时间很短而挂起等待的时间开销很大。考虑一个原语，通过该原语，调用进程测试一个互斥信号量，然后或者得到该信号量或者返回失败信息。</p>
<p>现在假设有一对进程使用两种资源。每个进程需要两种资源，它们利用轮询原语enter_region去尝试取得必要的锁，如果尝试失败，则该进程继续尝试。如果进程A先运行并得到资源1，然后进程2运行并得到资源2，以后不管哪一个进程运行，都不会有任何进展，但是哪一个进程也没有被阻塞。结果是两个进程总是一再消耗完分配给它们的CPU配额，<strong>但是没有进展也没有阻塞</strong>。因此，没有出现死锁现象（因为没有进程阻塞），但是从现象上看好像死锁发生了，这就是活锁（livelock）。</p>
<h2 id="死锁"><a href="#死锁" class="headerlink" title="死锁"></a>死锁</h2><p><a href="https://www.cyc2018.xyz/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%9F%BA%E7%A1%80/%E8%AE%A1%E7%AE%97%E6%9C%BA%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%20-%20%E6%AD%BB%E9%94%81.html" target="_blank" rel="noopener">参考</a></p>
<h3 id="必要条件"><a href="#必要条件" class="headerlink" title="必要条件"></a>必要条件</h3><p><img src="/img/noodle_plan/linux/dead_lock/dead_lock1.png" alt></p>
<p>(口诀互占不还？233):  </p>
<ul>
<li>互斥：每个资源要么已经分配给了一个进程，要么就是可用的。</li>
<li>占有和等待：已经得到了某个资源的进程可以再请求新的资源。</li>
<li>不可抢占：已经分配给一个进程的资源不能强制性地被抢占，它只能被占有它的进程显式地释放。</li>
<li>环路等待：有两个或者两个以上的进程组成一条环路，该环路中的每个进程都在等待下一个进程所占有的资源。</li>
</ul>
<h3 id="死锁处理方法大纲"><a href="#死锁处理方法大纲" class="headerlink" title="死锁处理方法大纲"></a>死锁处理方法大纲</h3><p>主要有以下四种方法：  </p>
<ul>
<li>鸵鸟策略</li>
<li>死锁检测与死锁恢复</li>
<li>死锁预防</li>
<li>死锁避免</li>
</ul>
<h3 id="鸵鸟策略"><a href="#鸵鸟策略" class="headerlink" title="鸵鸟策略"></a>鸵鸟策略</h3><p>把头埋在沙子里，假装根本没发生问题。<br>因为解决死锁问题的代价很高，因此鸵鸟策略这种不采取任务措施的方案会获得更高的性能。当发生死锁时不会对用户造成多大影响，或发生死锁的概率很低，可以采用鸵鸟策略。大多数操作系统，包括 Unix，Linux 和 Windows，处理死锁问题的办法仅仅是忽略它。</p>
<h3 id="死锁检测与死锁恢复"><a href="#死锁检测与死锁恢复" class="headerlink" title="死锁检测与死锁恢复"></a>死锁检测与死锁恢复</h3><p>不试图阻止死锁，而是当检测到死锁发生时，采取措施进行恢复。</p>
<h4 id="每种类型一个资源的死锁检测"><a href="#每种类型一个资源的死锁检测" class="headerlink" title="每种类型一个资源的死锁检测"></a>每种类型一个资源的死锁检测</h4><p><img src="/img/noodle_plan/linux/dead_lock/dead_lock2.png" alt></p>
<p>上图为资源分配图，其中方框表示资源，圆圈表示进程。资源指向进程表示该资源已经分配给该进程，进程指向资源表示进程请求获取该资源。</p>
<p>图 a 可以抽取出环，如图 b，它满足了环路等待条件，因此会发生死锁。</p>
<p>每种类型一个资源的死锁检测算法是通过检测有向图是否存在环来实现，从一个节点出发进行深度优先搜索，对访问过的节点进行标记，如果访问了已经标记的节点，就表示有向图存在环，也就是检测到死锁的发生。（当然也可以用拓扑排序思路来检测哈）</p>
<h4 id="每种类型多个资源的死锁检测"><a href="#每种类型多个资源的死锁检测" class="headerlink" title="每种类型多个资源的死锁检测"></a>每种类型多个资源的死锁检测</h4><p><img src="/img/noodle_plan/linux/dead_lock/dead_lock3.png" alt></p>
<p>上图中，有三个进程四个资源，每个数据代表的含义如下：</p>
<ul>
<li>E 向量：资源总量</li>
<li>A 向量：资源剩余量</li>
<li>C 矩阵：每个进程所拥有的资源数量，每一行都代表一个进程拥有资源的数量</li>
<li>R 矩阵：每个进程请求的资源数量</li>
</ul>
<p>进程 P<sub>1</sub> 和 P<sub>2</sub> 所请求的资源都得不到满足，只有进程 P<sub>3</sub> 可以，让 P<sub>3</sub> 执行，之后释放 P<sub>3</sub> 拥有的资源，此时 A = (2 2 2 0)。P<sub>2</sub> 可以执行，执行后释放 P<sub>2</sub> 拥有的资源，A = (4 2 2 1) 。P<sub>1</sub> 也可以执行。所有进程都可以顺利执行，没有死锁。</p>
<p>算法总结如下：</p>
<p>每个进程最开始时都不被标记，执行过程有可能被标记。当算法结束时，任何没有被标记的进程都是死锁进程。</p>
<ol>
<li>寻找一个没有标记的进程 P<sub>i</sub>，它所请求的资源小于等于 A。</li>
<li>如果找到了这样一个进程，那么将 C 矩阵的第 i 行向量加到 A 中，标记该进程，并转回 1。</li>
<li>如果没有这样一个进程，算法终止。</li>
</ol>
<h4 id="死锁恢复"><a href="#死锁恢复" class="headerlink" title="死锁恢复"></a>死锁恢复</h4><ul>
<li>利用抢占恢复</li>
<li>利用回滚恢复</li>
<li>通过杀死进程恢复</li>
</ul>
<h3 id="死锁预防"><a href="#死锁预防" class="headerlink" title="死锁预防"></a>死锁预防</h3><p>在程序运行之前预防发生死锁。</p>
<ul>
<li>破坏互斥条件<br>  例如假脱机打印机技术允许若干个进程同时输出，唯一真正请求物理打印机的进程是打印机守护进程。</li>
<li>破坏占有和等待条件<br>  一种实现方式是规定所有进程在开始执行前请求所需要的全部资源。</li>
<li>破坏不可抢占条件</li>
<li>破坏环路等待<br>  给资源统一编号，进程只能按编号顺序来请求资源。</li>
</ul>
<h3 id="死锁避免"><a href="#死锁避免" class="headerlink" title="死锁避免"></a>死锁避免</h3><p>在程序运行时避免发生死锁。避免死锁的主要算法是基于一个安全状态的概念。在描述算法前，我们先讨论有关安全的概念。</p>
<h4 id="安全状态的检测"><a href="#安全状态的检测" class="headerlink" title="安全状态的检测"></a>安全状态的检测</h4><p><img src="/img/noodle_plan/linux/dead_lock/dead_lock4.png" alt></p>
<p>图 a 的第二列 Has 表示已拥有的资源数，第三列 Max 表示总共需要的资源数，Free 表示还有可以使用的资源数。从图 a 开始出发，先让 B 拥有所需的所有资源（图 b），运行结束后释放 B，此时 Free 变为 5（图 c）；接着以同样的方式运行 C 和 A，使得所有进程都能成功运行，因此可以称图 a 所示的状态时安全的。</p>
<p><strong>安全状态的定义</strong>：如果没有死锁发生，并且即使所有进程突然请求对资源的最大需求，也仍然<strong>存在某种调度次序</strong>能够使得每一个进程运行完毕，则称该状态是安全的。</p>
<p>安全状态的检测与死锁的检测类似，因为安全状态必须要求不能发生死锁。下面的银行家算法与死锁检测算法非常类似，可以结合着做参考对比。</p>
<h4 id="单个资源的银行家算法"><a href="#单个资源的银行家算法" class="headerlink" title="单个资源的银行家算法"></a>单个资源的银行家算法</h4><p>Dijkstra（1965）提出了一种能够避免死锁的调度算法，称为银行家算法（banker’s algorithm），<br>一个小城镇的银行家，他向一群客户分别承诺了一定的贷款额度，算法要做的是判断对请求的满足是否会进入不安全状态，如果是，就拒绝请求；否则予以分配。</p>
<p><img src="/img/noodle_plan/linux/dead_lock/dead_lock5.png" alt></p>
<p>客户们各自做自己的生意，在某些时刻需要贷款（相当于请求资源）。在某一时刻，具体情况如图b所示。这个状态是安全的，由于保留着2个单位，银行家能够拖延除了C以外的其他请求。因而可以让C先完成，然后释放C所占的4个单位资源。有了这4个单位资源，银行家就可以给D或B分配所需的贷款单位，以此类推。</p>
<p>考虑假如向B提供了另一个他所请求的贷款单位，如图b所示，那么我们就有如图c所示的状态，该状态是不安全的。如果忽然所有的客户都请求最大的限额，而银行家无法满足其中任何一个的要求，那么就会产生死锁。不安全状态并不一定引起死锁，由于客户不一定需要其最大贷款额度，但银行家不敢抱这种侥幸心理。</p>
<p><strong>银行家算法就是对每一个请求进行检查，检查如果满足这一请求是否会达到安全状态。若是，那么就满足该请求；若否，那么就推迟对这一请求的满足。</strong>为了看状态是否安全，银行家看他是否有足够的资源满足某一个客户。如果可以，那么这笔投资认为是能够收回的，并且接着检查最接近最大限额的一个客户，以此类推。如果所有投资最终都被收回，那么该状态是安全的，最初的请求可以批准。</p>
<p>上图 c 为不安全状态，因此算法会拒绝之前的请求，从而避免进入图 c 中的状态。</p>
<h4 id="多个资源的银行家算法"><a href="#多个资源的银行家算法" class="headerlink" title="多个资源的银行家算法"></a>多个资源的银行家算法</h4><p><img src="/img/noodle_plan/linux/dead_lock/dead_lock6.png" alt></p>
<p>可以把银行家算法进行推广以处理多个资源  </p>
<p>上图中有五个进程，四个资源。左边的图表示已经分配的资源，右边的图表示还需要分配的资源。最右边的 E、P 以及 A 分别表示：总资源、已分配资源以及可用资源，注意这三个为向量，而不是具体数值，例如 A=(1020)，表示 4 个资源分别还剩下 1/0/2/0。</p>
<p>检查一个状态是否安全的算法如下：</p>
<ul>
<li>查找右边的矩阵是否存在一行小于等于向量 A。如果不存在这样的行，那么系统将会发生死锁，状态是不安全的。</li>
<li>假若找到这样一行，将该进程标记为终止，并将其已分配资源加到 A 中。</li>
<li>重复以上两步，直到所有进程都标记为终止，则状态时安全的。</li>
</ul>
<p>如果一个状态不是安全的，需要拒绝进入这个状态。</p>
<h2 id="linux进程调度"><a href="#linux进程调度" class="headerlink" title="linux进程调度"></a>linux进程调度</h2><p>参考 <a href="https://juejin.im/post/6844903568613310477" target="_blank" rel="noopener">https://juejin.im/post/6844903568613310477</a></p>
<p>在Linux中，线程和进程一视同仁，所以讲到进程调度，也包含了线程调度。</p>
<p>调度分两种:  </p>
<ul>
<li>非抢占式多任务<br>  除非任务自己结束，否则将会一直执行。</li>
<li><strong>抢占式多任务（Linux用的是这种)</strong><br>  这种情况下，由调度程序来决定什么时候停止一个进程的运行，这个强制的挂起动作即为<strong>抢占</strong>。采用抢占式多任务的基础是使用时间片轮转机制来为每个进程分配可以运行的时间单位。</li>
</ul>
<p>Linux有两种不同的进程优先级范围:</p>
<ul>
<li>使用nice值：越大的nice值意味着更低的优先级。 (-19 ~ 20之间)</li>
<li>实时优先级：可配置(通过实时调度API)，越高意味着进程优先级越高。</li>
</ul>
<p>任何实时的进程优先级都高于普通的进程，因此上面的两种优先级范围处于互不相交的范畴。</p>
<p>时间片：Linux中并不是以固定的时间值(如10ms)来分配时间片的，而是将处理器的使用比作为“时间片”划分给进程。这样，进程所获得的实际CPU时间就和系统的负载密切相关。</p>
<p>Linux内核有两个调度类：</p>
<ul>
<li>CFS(完全公平调度器Completely Fair Scheduler)</li>
<li>实时调度类。</li>
</ul>
<h3 id="公平调度CFS"><a href="#公平调度CFS" class="headerlink" title="公平调度CFS"></a>公平调度CFS</h3><p>举个例子来区分Unix调度和CFS, 有两个运行的优先级相同的进程:</p>
<ul>
<li>在Unix中可能是每个各执行5ms，执行期间完全占用处理器，但在“理想情况”下，应该是，能够在10ms内同时运行两个进程，每个占用处理器一半的能力。</li>
<li>CFS的做法是：CFS 调度程序并不采用严格规则来为一个优先级分配某个长度的时间片, 在所有可运行进程的总数上计算出一个进程应该运行的时间，nice值不再作为时间片分配的标准，而是用于处理计算获得的处理器使用权重。</li>
</ul>
<p>现在我们来看一个简单的例子，假设我们的系统只有两个进程在运行，一个是文本编辑器（I/O消耗型），另一个是视频解码器（处理器消耗型）。<br>理想的情况下，文本编辑器应该得到更多的处理器时间，至少当它需要处理器时，处理器应该立刻被分配给它（这样才能完成用户的交互），这也就意味着当文本编辑器被唤醒的时候，它应该抢占视频解码程序。<br>按照普通的情况，OS应该分配给文本编辑器更大的优先级和更多的时间片，但在Linux中，这两个进程都是普通进程，他们具有相同的nice值，因此它们将得到相同的处理器使用比（50%）。<br>但实际的运行过程中会发生什么呢？CFS将能够注意到，文本编辑器使用的处理器时间比分配给它的要少得多（因为大多时间在等待I/O），这种情况下，要实现所有进程“公平”地分享处理器，就会让文本编辑器在需要运行时立刻抢占视频解码器（每次都是如此）。</p>
<h3 id="实时调度"><a href="#实时调度" class="headerlink" title="实时调度"></a>实时调度</h3><p>Linux还实现了 POS1X实时调度扩展。这些扩展允许应用程序精确地控制如何分配CPU<br>给进程。运作在两个实时调度策略</p>
<ul>
<li>SCHED RR （循环）</li>
<li>SCHED FIFO （先入先出）</li>
</ul>
<p>下的进程的优先级总是高于运作在非实时策略下的进程。实时进程优先级的取值范围为1 （低）〜99<br>（高）。只有进程处于可运行状态，那么优先级更高的进程就会完全将优先级低的进程排除在<br>CPU之外。运作在SCHED_FIFO策略下的进程会互斥地访问CPU直到它执行终止或自动释放<br>CPU或被进入可运行状态的优先级更高的进程抢占。类似的规则同样适用于SCHED RR策略,<br>但在该策略下，如果存在多个进程运行于同样的优先级下，那么CPU就会以循环的方式被这<br>些进程共享。</p>
<p>实时调度采用 SCHED_FIFO 或 SCHED_RR 实时策略来调度的任何任务，与普通（非实时的）任务相比，具有更高的优先级。</p>
<p>Linux 采用两个单独的优先级范围，一个用于实时任务，另一个用于正常任务。实时任务分配的静态优先级为 0〜99，而正常任务分配的优先级为 100〜139。</p>
<p>这两个值域合并成为一个全局的优先级方案，其中较低数值表明较高的优先级。正常任务，根据它们的nice值，分配一个优先级；这里 -20 的nice值映射到优先级 100，而 +19 的nice值映射到 139。下图显示了这个方案。</p>
<p><img src="/img/noodle_plan/linux/process_scheduler.jpg" alt></p>
<h2 id="linux轻量级进程LWP"><a href="#linux轻量级进程LWP" class="headerlink" title="linux轻量级进程LWP"></a>linux轻量级进程LWP</h2><p>对于Linux操作系统而言，它对Thread的实现方式比较特殊。在Linux内核中，其实是没有线程的概念的，它把所有的线程当做标准的进程来实现，也就是说<strong>Linux内核，并没有为线程提供任何特殊的调度语义，也没有为线程实现特定的数据结构。取而代之的是，线程只是一个与其他进程共享某些资源的进程。</strong>每一个线程拥有一个唯一的task_struct结构，Linux内核它仅仅把线程当做一个正常的进程，或者说是轻量级进程，LWP(Lightweight processes)。</p>
<p>Linux线程与进程的区别，主要体现在资源共享、调度、性能几个方面，首先看一下资源共享方面。上面也提到，线程其实是共享了某一个进程的资源，这些资源包括：</p>
<ul>
<li>内存地址空间</li>
<li>进程基础信息</li>
<li>大部分数据</li>
<li>打开的文件</li>
<li>信号处理</li>
<li>当前工作目录</li>
<li>用户和用户组属性</li>
<li>…</li>
</ul>
<p>哪些是线程独自拥有的呢？</p>
<ul>
<li>线程ID</li>
<li>一系列的寄存器</li>
<li>栈的局部变量和返回地址</li>
<li>错误码 errno</li>
<li>信号掩码</li>
<li>优先级</li>
<li>…</li>
</ul>
<p>这里说一个黑科技，线程拥有独立的调用栈，除了栈之外共享了其他所有的段segment。但是由于线程间共享了内存，也就是说一个线程，理论上是可以访问到其他线程的调用栈的，可以用一个指针变量，去访问其他线程的局部栈帧，以访问其他线程的局部变量。</p>
<h3 id="LWP如何创建出来"><a href="#LWP如何创建出来" class="headerlink" title="LWP如何创建出来"></a>LWP如何创建出来</h3><p>那么Linux中线程是如何创建出来的呢？上面也提到，在Linux中线程是一种资源共享的方式，可以在创建进程的时候，指定某些资源是从其他进程共享的，从而在概念上创建了一个线程。在Linux中，可以通过clone系统调用来创建一个进程，它的函数签名如下：<br><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;sched.h&gt;</span></span></span><br><span class="line">int clone(int (*fn)(void *), void *child_stack, int flags, void *arg, ...);</span><br></pre></td></tr></table></figure></p>
<p>我们在使用clone创建进程的过程中，可以指明相应的参数，来决定共享某些资源，比如:<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">clone(CLONE_VM | CLONE_FS | CLONE_FILES | CLONE_SIGHAND, <span class="number">0</span>);</span><br></pre></td></tr></table></figure></p>
<p><strong>这个clone系统调用的行为类似于fork，不过新创建出来的进程，它的内存地址、文件系统资源、打开的文件描述符和信号处理器，都是共享父进程的。换句话说，这个新创建出来的进程，也被叫做Linux Thread</strong>。从这个例子中，也可以看出<strong>Linux中，线程其实是进程实现资源共享的一种方式。</strong></p>
<p>在内核中，clone调用经过参数传递和解释后会调用do_fork，这个核内函数同时也是fork、vfork系统调用的最终实现：<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">do_fork</span><span class="params">(<span class="keyword">unsigned</span> <span class="keyword">long</span> clone_flags, <span class="keyword">unsigned</span> <span class="keyword">long</span> stack_start, struct pt_regs* regs,<span class="keyword">unsigned</span> <span class="keyword">long</span> stack_size)</span></span>;</span><br></pre></td></tr></table></figure></p>
<p>在do_fork中，不同的clone_flags将导致不同的行为（共享不同的资源），下面列举几个flag的作用。 </p>
<ul>
<li>CLONE_VM<br>  如果do_fork时指定了CLONE_VM开关，创建的轻量级进程的内存空间将会和父进程指向同一个地址，即创建的轻量级进程将与父进程共享内存地址空间。</li>
<li>CLONE_FS<br>  如果do_fork时指定了CLONE_FS开关，对于轻量级进程则会与父进程共享相同的所在文件系统的根目录和当前目录信息。也就是说，轻量级进程没有独立的文件系统相关的信息，进程中任何一个线程改变当前目录、根目录等信息都将直接影响到其他线程。</li>
<li>CLONE_FILES<br>  如果do_fork时指定了CLONE_FILES开关，创建的轻量级进程与父进程将会共享已经打开的文件。这一共享使得任何线程都能访问进程所维护的打开文件，对它们的操作会直接反映到进程中的其他线程。</li>
<li>CLONE_SIGHAND<br>  如果do_fork时指定了CLONE_FILES开关，轻量级进程与父进程将会共享对信号的处理方式。也就是说，子进程与父进程的信号处理方式完全相同，而且可以相互更改。</li>
</ul>
<p>尽管linux支持轻量级进程，但并不能说它就支持内核线程，因为linux的”线程”和”进程”实际上处于一个调度层次，共享一个进程标识符空间，这种限制使得不可能在linux上实现完全意义上的POSIX线程机制，因此众多的linux线程库实现尝试都只能尽可能实现POSIX的绝大部分语义，并在功能上尽可能逼近。</p>
<h2 id="多核CPU是否能同时执行多个进程？"><a href="#多核CPU是否能同时执行多个进程？" class="headerlink" title="多核CPU是否能同时执行多个进程？"></a>多核CPU是否能同时执行多个进程？</h2><p>多核的作用就是每个CPU可以调度不同的任务“并行”执行。注意，这里说的是“并行”，而不是“并发”，所以问题的回答是“能”。</p>
<p>第二个问题，“同时最多执行几个进程“?<br>这里你想描述的“同时”的意思，是某一个特定时刻吗？如果是，很明显，在某一特定时刻，每个核只能调度一个任务执行，所以有多少个核最多就可以调度多少个进程（或者说成线程比较准确些）。但在一段时间之内，每个核可以“并发”调度多个任务执行。如何“并发”，这就是由不同操作系统的进程调度策略规定的了，比如常见Linux的CFS调度算法和Windows的抢占式调度算法。</p>
<h2 id="创建守护进程的步骤"><a href="#创建守护进程的步骤" class="headerlink" title="创建守护进程的步骤"></a>创建守护进程的步骤</h2><p>(两fork一set, u工文dev)<br>最关键的三步骤:</p>
<ol>
<li><p>调用fork，然后使父进程exit。<br>虽然子进程继承了父进程的进程组ID，但获得了一个新的进程ID，这就保证了子进程不是一个进程组的组长进程。这是下面将要进行的setsid调用的先决条件。</p>
</li>
<li><p>调用setsid创建一个新会话。<br>使调用进程：(a)成为新会话的首进程，(b)成为一个新进程组的组长进程．(c)没有控制终端。也可概括为 : 开启一个新会话并释放它与控制终端之间的所有关联关系</p>
</li>
<li><p>再次fork并杀掉首进程.<br>这样就确保了子进程不是一个会话首进程， 根据linux中获取终端的规则（只有会话首进程才能请求一个控制终端）， 这样进程永远不会重新请求一个控制终端</p>
</li>
</ol>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">                   会      话</span><br><span class="line">                 /     |      \</span><br><span class="line">               /       |       \</span><br><span class="line">             /         |         \</span><br><span class="line">     前台进程组     后台进程组1     后台进程组2 ...</span><br><span class="line">   /    |   \     /    |   \      /    |   \</span><br><span class="line">进程1 进程2 ...  进程3 进程4 ...       ...</span><br></pre></td></tr></table></figure>
<h2 id="进程组"><a href="#进程组" class="headerlink" title="进程组"></a>进程组</h2><p>进程组就是一系列相互关联的进程集合，系统中的每一个进程也必须从属于某一个进程组；每个进程组中都会有一个唯一的 ID(process group id)，简称 PGID；PGID 一般等同于进程组的创建进程的 Process ID，而这个进进程一般也会被称为进程组先导 (process group leader)</p>
<h2 id="会话"><a href="#会话" class="headerlink" title="会话"></a>会话</h2><p>会话（session）是一个若干进程组的集合，同样的，系统中每一个进程组也都必须从属于某一个会话；一个会话只拥有最多一个控制终端（也可以没有），该终端为会话中所有进程组中的进程所共用。一个会话中前台进程组只会有一个，只有其中的进程才可以和控制终端进行交互；除了前台进程组外的进程组，都是后台进程组；和进程组先导类似，会话中也有会话先导 (session leader) 的概念，用来表示建立起到控制终端连接的进程。在拥有控制终端的会话中，session leader 也被称为控制进程(controlling process)，一般来说控制进程也就是登入系统的 shell 进程(login shell)；</p>
<h2 id="杀死进程组或会话中的所有进程"><a href="#杀死进程组或会话中的所有进程" class="headerlink" title="杀死进程组或会话中的所有进程"></a>杀死进程组或会话中的所有进程</h2><p>我们可以使用该 PGID，通过 kill 命令向整个进程组发送信号：</p>
<p><code>kill -SIGTERM -- -19701</code></p>
<p>我们用一个负数 -19701 向进程组发送信号。如果我们传递的是一个正数，这个数将被视为进程 ID 用于终止进程。如果我们传递的是一个负数，它被视为 PGID，用于终止整个进程组。<br>负数来自系统调用的直接定义。</p>
<p>杀死会话中的所有进程与之完全不同。有些系统没有会话 ID 的概念。即使是具有会话 ID 的系统，例如 Linux，也没有提供系统调用来终止会话中的所有进程。你需要遍历 /proc 输出的进程树，收集所有的 SID，然后一一终止进程。<br>Pgrep 实现了遍历、收集并通过会话 ID 杀死进程的算法。使用以下命令：</p>
<p><code>pkill -s &lt;SID&gt;</code></p>
<h2 id="SIGHUP"><a href="#SIGHUP" class="headerlink" title="SIGHUP"></a>SIGHUP</h2><p>SIGHUP 会在以下 3 种情况下被发送给相应的进程：</p>
<ul>
<li>终端关闭时，该信号被发送到 session 首进程以及作为 job 提交的进程（即用 &amp; 符号提交的进程）；</li>
<li>session 首进程退出时，该信号被发送到该 session 中的前台进程组中的每一个进程；</li>
<li>若父进程退出导致进程组成为孤儿进程组，且该进程组中有进程处于停止状态（收到 SIGSTOP 或 SIGTSTP 信号），该信号会被发送到该进程组中的每一个进程。</li>
</ul>
<p>例如：在我们登录 Linux 时，系统会分配给登录用户一个终端 (Session)。在这个终端运行的所有程序，包括前台进程组和后台进程组，一般都属于这个 Session。当用户退出 Linux 登录时，前台进程组和后台有对终端输出的进程将会收到 SIGHUP 信号。这个信号的默认操作为终止进程，因此前台进程组和后台有终端输出的进程就会中止。<br><strong>此外，对于与终端脱离关系的守护进程，正常情况下是永远都收不到这个信号的, 所以可以人为的发SIGHUP信号给她用于通知它做一些想要的自定义的操作</strong>, 比较常见的如重新读取配置文件操作。 比如 xinetd 超级服务程序。</p>
<h2 id="SIGCHLD与僵死进程"><a href="#SIGCHLD与僵死进程" class="headerlink" title="SIGCHLD与僵死进程"></a>SIGCHLD与僵死进程</h2><p>SIGCHLD信号,子进程结束时, 父进程会收到这个信号。如果父进程没有处理这个信号，也没有等待(waitpid)子进程，子进程虽然终止，但是还会在内核进程表中占有表项，这时的子进程称为僵尸进程。这种情 况我们应该捕捉它，或者wait它派生的子进程，或者父进程先终止，这时子进程的终止自动由init进程 来接管</p>
<h2 id="SIGPIPE"><a href="#SIGPIPE" class="headerlink" title="SIGPIPE"></a>SIGPIPE</h2><p>在网络编程中，SIGPIPE 这个信号是很常见的。当往一个写端关闭的管道或 socket 连接中连续写入数据时会引发 SIGPIPE 信号, 引发 SIGPIPE 信号的写操作将设置 errno 为 EPIPE。在 TCP 通信中，当通信的双方中的一方 close 一个连接时，若另一方接着发数据，根据 TCP 协议的规定，会收到一个 RST 响应报文，若再往这个服务器发送数据时，系统会发出一个 SIGPIPE 信号给进程，告诉进程这个连接已经断开了，不能再写入数据。</p>
<p>因为 SIGPIPE 信号的默认行为是结束进程，而我们绝对不希望因为写操作的错误而导致程序退出，尤其是作为服务器程序来说就更恶劣了。所以我们应该对这种信号加以处理，在这里，介绍处理 SIGPIPE 信号的方式：</p>
<p>一般给 SIGPIPE 设置 SIG_IGN 信号处理函数，忽略该信号:</p>
<p><code>signal(SIGPIPE, SIG_IGN);</code></p>
<p>前文说过，引发 SIGPIPE 信号的写操作将设置 errno 为 EPIPE,。所以，第二次往关闭的 socket 中写入数据时, 会返回 - 1, 同时 errno 置为 EPIPE. 这样，便能知道对端已经关闭，然后进行相应处理，而不会导致整个进程退出.</p>
<h2 id="内核态与用户态的区别"><a href="#内核态与用户态的区别" class="headerlink" title="内核态与用户态的区别"></a>内核态与用户态的区别</h2><ul>
<li>内核态：cpu可以访问内存的所有数据，包括外围设备，例如硬盘，网卡，cpu也可以将自己从一个程序切换到另一个程序。</li>
<li>用户态：只能受限的访问内存，且不允许访问外围设备，占用cpu的能力被剥夺，cpu资源可以被其他程序获取。</li>
</ul>
<p>从用户态到内核态切换可以通过三种方式：</p>
<ul>
<li>系统调用: 其实系统调用本身就是中断，但是软件中断，跟硬中断不同。</li>
<li>异常：如果当前进程运行在用户态，如果这个时候发生了异常事件，就会触发切换。例如：缺页异常。</li>
<li>外设中断：当外设完成用户的请求时，会向CPU发送中断信号。</li>
</ul>

          
        
      


      

    
      <footer class="post-footer">
        

        

        

        
        
          <div class="post-eof"></div>
        
      </footer>
      
    </div>
    
    
    

    

    

    

  </div>
  
  
  
  </article>


      
    
      
        

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://hulinhong.com/2021/02/26/quic_intro/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="no5ix">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/uploads/avatar.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="烫">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2021/02/26/quic_intro/" itemprop="url">QUIC原理与KCP会话握手借鉴</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2021-02-26T18:08:06+00:00">
                2021-02-26
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/NP/" itemprop="url" rel="index">
                    <span itemprop="name">NP</span>
                  </a>
                </span>

                
                
              
            </span>
          

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    




    
    
    
    <div class="post-body" itemprop="articleBody">
      
      

      

      
      
        <div class="post-eof"></div>
      

      
      

      
        
          
            <p>参考: </p>
<ul>
<li><a href="https://zhuanlan.zhihu.com/p/142794794" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/142794794</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/32553477" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/32553477</a></li>
</ul>
<p>本文主要介绍 QUIC 协议产生的背景和核心特性。</p>
<h1 id="写在前面"><a href="#写在前面" class="headerlink" title="写在前面"></a>写在前面</h1><p>如果你的 App，在不需要任何修改的情况下就能提升 15% 以上的访问速度。特别是弱网络的时候能够提升 20% 以上的访问速度。</p>
<p>如果你的 App，在频繁切换 4G 和 WIFI 网络的情况下，不会断线，不需要重连，用户无任何感知。如果你的 App，既需要 TLS 的安全，也想实现 HTTP2 多路复用的强大。</p>
<p>如果你刚刚才听说 HTTP2 是下一代互联网协议，如果你刚刚才关注到 TLS1.3 是一个革命性具有里程碑意义的协议，但是这两个协议却一直在被另一个更新兴的协议所影响和挑战。</p>
<p>如果这个新兴的协议，它的名字就叫做 “快”，并且正在标准化为新一代的互联网传输协议。</p>
<p>你愿意花一点点时间了解这个协议吗？你愿意投入精力去研究这个协议吗？你愿意全力推动业务来使用这个协议吗？</p>
<h1 id="QUIC-概述"><a href="#QUIC-概述" class="headerlink" title="QUIC 概述"></a>QUIC 概述</h1><p>Quic 全称 quick udp internet connection [1]，“快速 UDP 互联网连接”，（和英文 quick 谐音，简称 “快”）是由 google 提出的使用 udp 进行多路并发传输的协议。</p>
<p>Quic 相比现在广泛应用的 http2+tcp+tls 协议有如下优势 [2]：</p>
<ol>
<li>减少了 TCP 三次握手及 TLS 握手时间。</li>
<li>改进的拥塞控制。</li>
<li>避免队头阻塞的多路复用。</li>
<li>连接迁移。</li>
<li>前向冗余纠错。</li>
</ol>
<h1 id="TCP的缺陷"><a href="#TCP的缺陷" class="headerlink" title="TCP的缺陷"></a>TCP的缺陷</h1><p>从上个世纪 90 年代互联网开始兴起一直到现在，大部分的互联网流量传输只使用了几个网络协议。使用 IPv4 进行路由，使用 TCP 进行连接层面的流量控制，使用 SSL/TLS 协议实现传输安全，使用 DNS 进行域名解析，使用 HTTP 进行应用数据的传输。</p>
<p>而且近三十年来，这几个协议的发展都非常缓慢。TCP 主要是拥塞控制算法的改进，SSL/TLS 基本上停留在原地，几个小版本的改动主要是密码套件的升级，TLS1.3[3] 是一个飞跃式的变化，但截止到今天，还没有正式发布。IPv4 虽然有一个大的进步，实现了 IPv6，DNS 也增加了一个安全的 DNSSEC，但和 IPv6 一样，部署进度较慢。</p>
<p>随着移动互联网快速发展以及物联网的逐步兴起，网络交互的场景越来越丰富，网络传输的内容也越来越庞大，用户对网络传输效率和 WEB 响应速度的要求也越来越高。</p>
<p>一方面是历史悠久使用广泛的古老协议，另外一方面用户的使用场景对传输性能的要求又越来越高。如下几个由来已久的问题和矛盾就变得越来越突出。</p>
<ol>
<li>协议历史悠久导致中间设备僵化。</li>
<li>依赖于操作系统的实现导致协议本身僵化。</li>
<li>建立连接的握手延迟大。</li>
<li>队头阻塞。</li>
</ol>
<p>这里分小节简单说明一下：</p>
<h2 id="中间设备的僵化"><a href="#中间设备的僵化" class="headerlink" title="中间设备的僵化"></a>中间设备的僵化</h2><p>可能是 TCP 协议使用得太久，也非常可靠。所以我们很多中间设备，包括防火墙、NAT 网关，整流器等出现了一些约定俗成的动作。</p>
<p>比如有些防火墙只允许通过 80 和 443，不放通其他端口。NAT 网关在转换网络地址时重写传输层的头部，有可能导致双方无法使用新的传输格式。整流器和中间代理有时候出于安全的需要，会删除一些它们不认识的选项字段。</p>
<p>TCP 协议本来是支持端口、选项及特性的增加和修改。但是由于 TCP 协议和知名端口及选项使用的历史太悠久，中间设备已经依赖于这些潜规则，所以对这些内容的修改很容易遭到中间环节的干扰而失败。</p>
<p>而这些干扰，也导致很多在 TCP 协议上的优化变得小心谨慎，步履维艰。</p>
<h2 id="依赖于操作系统的实现导致协议僵化"><a href="#依赖于操作系统的实现导致协议僵化" class="headerlink" title="依赖于操作系统的实现导致协议僵化"></a>依赖于操作系统的实现导致协议僵化</h2><p>TCP 是由操作系统在内核西方栈层面实现的，应用程序只能使用，不能直接修改。虽然应用程序的更新迭代非常快速和简单。但是 TCP 的迭代却非常缓慢，原因就是操作系统升级很麻烦。</p>
<p>现在移动终端更加流行，但是移动端部分用户的操作系统升级依然可能滞后数年时间。PC 端的系统升级滞后得更加严重，windows xp 现在还有大量用户在使用，尽管它已经存在快 20 年。</p>
<p>服务端系统不依赖用户升级，但是由于操作系统升级涉及到底层软件和运行库的更新，所以也比较保守和缓慢。</p>
<p>这也就意味着即使 TCP 有比较好的特性更新，也很难快速推广。比如 TCP Fast Open。它虽然 2013 年就被提出了，但是 Windows 很多系统版本依然不支持它。</p>
<h2 id="建立连接的握手延迟大"><a href="#建立连接的握手延迟大" class="headerlink" title="建立连接的握手延迟大"></a>建立连接的握手延迟大</h2><p>不管是 HTTP1.0/1.1 还是 HTTPS，HTTP2，都使用了 TCP 进行传输。HTTPS 和 HTTP2 还需要使用 TLS 协议来进行安全传输。这就出现了两个握手延迟：</p>
<p>1.TCP 三次握手导致的 TCP 连接建立的延迟。</p>
<p>2.TLS 完全握手需要至少 2 个 RTT 才能建立，简化握手需要 1 个 RTT 的握手延迟。</p>
<p>对于很多短连接场景，这样的握手延迟影响很大，且无法消除。</p>
<h2 id="队头阻塞"><a href="#队头阻塞" class="headerlink" title="队头阻塞"></a>队头阻塞</h2><p>队头阻塞主要是 TCP 协议的可靠性机制引入的。TCP 使用序列号来标识数据的顺序，数据必须按照顺序处理，如果前面的数据丢失，后面的数据就算到达了也不会通知应用层来处理。</p>
<p>另外 TLS 协议层面也有一个队头阻塞，因为 TLS 协议都是按照 record 来处理数据的，如果一个 record 中丢失了数据，也会导致整个 record 无法正确处理。</p>
<p>概括来讲，TCP 和 TLS1.2 之前的协议存在着结构性的问题，如果继续在现有的 TCP、TLS 协议之上实现一个全新的应用层协议，依赖于操作系统、中间设备还有用户的支持。部署成本非常高，阻力非常大。</p>
<p>所以 QUIC 协议选择了 UDP，因为 UDP 本身没有连接的概念，不需要三次握手，优化了连接建立的握手延迟，同时在应用程序层面实现了 TCP 的可靠性，TLS 的安全性和 HTTP2 的并发性，只需要用户端和服务端的应用程序支持 QUIC 协议，完全避开了操作系统和中间设备的限制。</p>
<h1 id="0RTT建立连接"><a href="#0RTT建立连接" class="headerlink" title="0RTT建立连接"></a>0RTT建立连接</h1><p>现如今，高速且安全的网络接入服务已经成为人们的必须。传统 TCP+TLS 构建的安全互联服务，升级与补丁更新时有提出（如 TCP Fastopen，新的 TLS 1.3），但是由于基础设施僵化，升级与应用困难。为解决这个问题，Google 另辟蹊径在 UDP 的基础上实现了带加密的更好的 TCP–QUIC（Quick UDP Internet Connection), 一种基于 UDP 的低时延的互联网传输层协议。近期成立了 Working Group 也将 QUIC 作为制定 HTTP 3.0 的标准的基础, 说明 QUIC 的应用前景美好。本文单独就网络传输的建连问题展开了分析, 浅析了建连时间对传输的影响, 以及 QUIC 的 0-RTT 建连是如何解决建连耗时长的问题的。在此基础上, 结合 QUIC 的源码, 浅析了 QUIC 的基本实现, 并描述一种可供参考的分布式环境下的 0-RTT 的落地实践方案。</p>
<p>以一次简单的 HTTPS 请求（example.com）为例（假设访问 example.com 时返回的内容较小，server 端可以在一个数据包里返回响应），为获取请求资源。需要经过以下 4 个步骤：</p>
<ol>
<li>DNS 查询 example.com 获取 IP。DNS 服务一般默认是由你的 ISP 提供，ISP 通常都会有缓存的，这部分时间能适当减少；</li>
<li>TCP 握手，我们熟悉的 TCP 三次握手需要需要 1 个 RTT；</li>
<li>TLS 握手，以目前应用最广泛的 TLS 1.2 而言，需要 2 个 RTT。对于非首次建连, 可以选择启用会话重用 (Session Resumption)，则可缩小握手时间到 1 个 RTT；</li>
<li>HTTP 业务数据交互，假设 example.com 的数据在一次交互就能取回来。那么业务数据的交互需要 1 个 RTT； 经过上面的过程分析可知，要完成一次简短的 HTTPS 业务数据交互，需要经历：</li>
</ol>
<ul>
<li>新连接：4RTT + DNS。</li>
<li>会话重用：3RTT + DNS</li>
</ul>
<p>尤其对于小数据量的交互而言，抛开 DNS 查询时间, 建连时间占剩下的总时间的 2/3 至 3/4 不等，影响不可小觑。加之如果用户网络不好，RTT 延时大的话，建连时间可能耗费数百毫秒至数秒不等，这将极大的影响用户体验。究其原因一方面是 TCP 和 TLS 分层设计导致的：分层的设计需要每个逻辑层次分别建立自己的连接状态。另一方面是 TLS 的握手阶段复杂的密钥协商机制导致的。要降低建连耗时，需要从这两方面着手。</p>
<p>针对 TLS 的握手阶段复杂的密钥协商机问题, TLS 1.3 精简了握手交互过程, 实现了 1-RTT 握手。在会话重用类似的理念的基础上, 对非首次握手会话, 可以进一步实现 0-RTT 握手 (在刚开始 TLS 密钥协商的时候，就能附送一部分经过加密的数据传递给对方)。由于 TLS 是建立在 TCP 之上的, 0-RTT 没有计算 TCP 层的握手开销, 因而对用户来说, 发送数据之前还是要经历 TCP 层的 1RTT 握手, 因而不是真正的 0-RTT 握手。</p>
<blockquote>
<p>TLS 1.3 为实现 0-RTT，需要双方在刚开始建立连接的时候就已经持有一个对称密钥，这个密钥在 TLS 1.3 中称为 PSK（Pre-Shared-Key）。PSK 是 TLS 1.2 中的会话重用 (Session Resumption) 机制的一个升级，TLS 1.3 握手结束后，服务器可以发送一个 NST（New-Session-Ticket）的报文给客户端，该报文中记录 PSK 的值、名字和有效期等信息，双方下一次建立连接可以使用该 PSK 值作为初始密钥材料。因为 PSK 是从以前建立的安全信道中获得的，只要证明了双方都持有相同的 PSK，不再需要证书认证，就可以证明双方的身份(因此 PSK 也是一种身份认证机制)。TLS 1.3 新加了 Early Data 类型的报文, 用于在 0-RTT 的握手阶段传递应用层数据, 实现了握手的同时就能附带加密的应用层数据从而实现 0-RTT。</p>
<p>TLS 1.3 的 0-RTT 特性不能防止重放攻击, 需要业务在使用时评估是否有重放攻击风险。如有相关风险的话, 可能需要酌情考虑禁用 0-RTT 特性。</p>
</blockquote>
<p>下图对比了 TLS 各版本与场景下的延时对比:<br><img src="/img/quic_intro/quic_intro_1.jpg" alt></p>
<p>TLS 各版本与场景下的耗时</p>
<p>从对比我们可以看到, 即使用上了 TLS 1.3, 精简了握手过程, 最快能做到 0-RTT 握手 (首次是 1-RTT), 但是对用户感知而言, 还要加上 1RTT 的 TCP 握手开销。 Google 有提出 Fastopen 的方案来使得 TCP 非首次握手就能附带用户数据, 但是由于 TCP 实现僵化, 无法升级应用, 相关 RFC 到现今都是 experimental 状态。这种分层设计带来的延时, 有没有办法进一步降低呢? QUIC 通过合并加密与连接管理解决了这个问题, 我们来看看其是如何实现真正意义上的 0-RTT 的握手, 让与 server 进行第一个数据包的交互就能带上用户数据。</p>
<p>QUIC 为规避 TCP 协议僵化的问题，将 QUIC 协议建立在了 UDP 之上。考虑到安全性是网络的必备选项，加密在 QUIC 里强制的。传输方面参考 TCP 并充分优化了 TCP 多年发现的缺陷和不足, 实现了一套端到端的可靠加密传输。通过将加密和连接管理两层合二为一，消除了当前 TCP+TLS 的分层设计传输引入的时延。</p>
<p>同 TLS 的握手一样, QUIC 的加密握手的核心在于协商出一个加密会话数据的对称密钥。QUIC 的握手使用了 DH 密钥协商算法来协商一个对称密钥。DH 密钥协商算法简单来讲, 需要通信双方各自生成自己的非对称公私钥对, 双发各自保留自己的私钥, 将公钥发给对方, 利用对方的公钥和自己的私钥可以运算出同一个对称密钥。详细的原理这里不展开叙述, 有专业的<a href="https://book.douban.com/subject/19986936/" target="_blank" rel="noopener">密码学书籍</a>对其原理有详细的论述, 网上也有很多好的教程对其由深入浅出的总结, 如<a href="https://labuladong.gitbook.io/algo/di-wu-zhang-ji-suan-ji-ji-shu/mi-ma-ji-shu" target="_blank" rel="noopener">这一篇</a>。</p>
<p>如上所述, DH 密钥协商需要通行双方各自生成自己的非对称公私钥对。server 端与客户端的关系是 1 对 N 的关系, 明显 server 端生成一份公私钥对, 让 N 个客户端公用, 能明显减少生成开销, 降低管理的成本。server 端的这份公私钥对就是专门用于握手使用的, 客户端一经获取, 就可以缓存下来后续建连时继续使用, 这个就是达成 0-RTT 握手的关键, 因此 server 生成的这份公钥称为 0-RTT 握手公钥。真正的握手过程是这样 (简化了实现细节):</p>
<ol>
<li>server 端在握手开始前，server 端需要首先生成 (或加载使用上次保存下来的) 握手公私钥对, 该份公私钥对是所有客户端共享的。</li>
<li>client 端首次握手时, client 对 server 一无所知, 需要 1 个 RTT 来询问 server 端的握手公钥 (实际的握手交互还会发送诸如版本等其他数据) 并缓存下来。本步骤只在首次建连时发生(0-RTT 握手公钥的过期也会导致需要重走这一步), 但这种情况很少发生, 影响很小(也没办法避免)。</li>
<li>client 收到 server 端返回这份握手公钥后，生成自己的临时公私钥对后, 计算出共享的对称密钥后, 加密好数据, 并连同 client 的公钥一并发给 server 端。照 DH 密钥协商的原理, 此处已经可以协商出每条会话不一样的会话密钥了 (因为每个 client 生成的公私钥是不同的), 是不是拿这个来加密会话数据就行了呢? 真实的情况不是这样的!</li>
<li>server 端会再次生成一份临时的公私钥对，使用这份临时的私钥与客户端的公钥运算出最终的会话对称密钥。接下来 server 会拿这个最终的会话密钥加密应用层数据, 连同这份临时的 server 端公钥一并发给 client 端, client 端收到后可以按照 DH 的原理依瓢画葫会恢复出最终的会话对称密钥。后续所有的数据都是用最终的会话对称密钥进行加密。server 侧这个动作是不是多此一举呢? 不是的, 这么做的目的是为了获取所谓的前向安全特性: 因为 server 端的后面生成的这份公私钥是临时生成的, 不会保存下来，也就杜绝了密钥泄漏导致会话数据被恶意收集后的被解密掉的风险。</li>
</ol>
<p>首次握手要多一个 RTT 询问 server 端的 0-RTT 握手公钥, 此询问过程不携带任何应用层数据, 因此是 1-RTT 握手。在首次握手完成后, client 端可以缓存下第一次询问获知的 server 端的公钥信息, 后续的连接过程可以跳过询问，直接使用缓存的 server 端的公钥。公钥信息在 QUIC 的实现里是保存在握手数据包里的 SCFG 中的 (Server Config), 获取 0-RTT 握手公钥就是要获取 SCFG, 后续均以获取 SCFG 代替。详细的握手过程, 可以参见 <a href="https://blog.csdn.net/dog250/article/details/80935534" target="_blank" rel="noopener">dog250</a> 博客文章的详细叙述。</p>
<blockquote>
<p>从上面的分析可知，0-RTT 握手的首次交互，server 端使用的是保存下来的握手密钥，因而没有无法做到前向安全，不能防止重放攻击, 需要业务在使用时评估是否有重放攻击风险。</p>
</blockquote>
<p><img src="/img/quic_intro/quic_intro_1_2.jpg" alt></p>
<p>QUIC 0-RTT 握手</p>
<p>上文简述了 QUIC 握手的密钥协商过程，首次需要询问一次 Server 以获取 SCFG, 从而获取存储于其中的 0-RTT 握手公钥。这一交互过程中 client 和 server 在 QUIC 的握手协议发送的报文中分别叫 Inchoate Client hello message (inchoate CHLO) 和 Rejection message (REJ)。因而包含 server 端的握手公钥的 SCFG 是在 REJ 报文中发给客户端的。有了 SCFG，接下来就能发起 0-RTT 握手。这一过程中 client 和 server 端在 QUIC 的握手协议发送的报文中分别叫 Full Client Hello message (full CHLO) 和 Server Hello message (SHLO)。下图摘自 Google QUIC 握手协议的官方文档，详细叙述了握手过程 client 侧的处理流程：</p>
<p>QUIC 握手客户端侧处理流程<br><img src="/img/quic_intro/quic_intro_1_3.jpg" alt></p>
<h2 id="0RTT的重放攻击风险"><a href="#0RTT的重放攻击风险" class="headerlink" title="0RTT的重放攻击风险"></a>0RTT的重放攻击风险</h2><p>0-RTT连接恢复并非那么简单，它会带来许多意外风险及警告，这正是为什么有些默认程序不启用0-RTT连接恢复的原因。用户必须提前考虑所涉及的风险，并做出决定是否使用此功能。可以在应用程序层面使用预防措施来减轻这种情况。</p>
<p>首先，0-RTT连接恢复是不提供forwardsecrecy的，针对连接的secret parameters的妥协将微不足道地允许恢复新连接0-RTT阶段期间，发送applicationdata 进行特定的妥协。</p>
<p>在0-RTT阶段之后、或握手之后发送的数据，仍然是安全的。这是因为TLS1.3 (及QUIC)还是会对handshakecompletion之后发送的数据执行normal key exchange algorithm (这是forwardsecret) 。</p>
<p>值得注意的是，在0-RTT期间发送的applicationdata 可以被路径上的on-path attacker 捕获，然后多次重播到同一个服务器。这个在大部分情况下也许不是问题，因为attacker无法解密数据，0-RTT连接恢复还是非常有用的。在其他的情况下，这可能会引起出乎意料的风险。</p>
<p>举个比例，假设一家银行允许authenticated user (e.g using HTTPcookie, 或其他HTTP身份验证机制)通过specificAPI endpoint发出HTTP请求将资金从其账户发送到另一个用户。</p>
<p>如果attacker能够在使用0-RTT连接恢复时捕获该请求，他们将无法看到plaintext并且获取用户的凭据，原因是因为他们不知道用于加密数据的secretkey；但是他们仍然有可能一直散发重复性地请求，耗尽该用户的银行账户里的钱。</p>
<p><img src="/img/quic_intro/quic_intro_1_4.jpg" alt></p>
<h1 id="改进的拥塞控制"><a href="#改进的拥塞控制" class="headerlink" title="改进的拥塞控制"></a>改进的拥塞控制</h1><p>TCP 的拥塞控制实际上包含了四个算法：慢启动，拥塞避免，快速重传，快速恢复 [22]。</p>
<p>QUIC 协议当前默认使用了 TCP 协议的 Cubic 拥塞控制算法 [6]，同时也支持 CubicBytes, Reno, RenoBytes, BBR, PCC 等拥塞控制算法。</p>
<p>从拥塞算法本身来看，QUIC 只是按照 TCP 协议重新实现了一遍，那么 QUIC 协议到底改进在哪些方面呢？主要有如下几点：</p>
<h1 id="可插拔"><a href="#可插拔" class="headerlink" title="可插拔"></a>可插拔</h1><p>什么叫可插拔呢？就是能够非常灵活地生效，变更和停止。体现在如下方面：</p>
<ol>
<li>应用程序层面就能实现不同的拥塞控制算法，不需要操作系统，不需要内核支持。这是一个飞跃，因为传统的 TCP 拥塞控制，必须要端到端的网络协议栈支持，才能实现控制效果。而内核和操作系统的部署成本非常高，升级周期很长，这在产品快速迭代，网络爆炸式增长的今天，显然有点满足不了需求。</li>
<li>即使是单个应用程序的不同连接也能支持配置不同的拥塞控制。就算是一台服务器，接入的用户网络环境也千差万别，结合大数据及人工智能处理，我们能为各个用户提供不同的但又更加精准更加有效的拥塞控制。比如 BBR 适合，Cubic 适合。</li>
<li>应用程序不需要停机和升级就能实现拥塞控制的变更，我们在服务端只需要修改一下配置，reload 一下，完全不需要停止服务就能实现拥塞控制的切换。</li>
</ol>
<p>STGW 在配置层面进行了优化，我们可以针对不同业务，不同网络制式，甚至不同的 RTT，使用不同的拥塞控制算法。</p>
<h1 id="单调递增的-Packet-Number"><a href="#单调递增的-Packet-Number" class="headerlink" title="单调递增的 Packet Number"></a>单调递增的 Packet Number</h1><p>TCP 为了保证可靠性，使用了基于字节序号的 Sequence Number 及 Ack 来确认消息的有序到达。</p>
<p>QUIC 同样是一个可靠的协议，它使用 Packet Number 代替了 TCP 的 sequence number，并且每个 Packet Number 都严格递增，也就是说就算 Packet N 丢失了，重传的 Packet N 的 Packet Number 已经不是 N，而是一个比 N 大的值。而 TCP 呢，重传 segment 的 sequence number 和原始的 segment 的 Sequence Number 保持不变，也正是由于这个特性，引入了 Tcp 重传的歧义问题。</p>
<p><img src="/img/quic_intro/quic_intro_2.jpg" alt></p>
<p>如上图所示，超时事件 RTO 发生后，客户端发起重传，然后接收到了 Ack 数据。由于序列号一样，这个 Ack 数据到底是原始请求的响应还是重传请求的响应呢？不好判断。</p>
<p>如果算成原始请求的响应，但实际上是重传请求的响应（上图左），会导致采样 RTT 变大。如果算成重传请求的响应，但实际上是原始请求的响应，又很容易导致采样 RTT 过小。</p>
<p>由于 Quic 重传的 Packet 和原始 Packet 的 Pakcet Number 是严格递增的，所以很容易就解决了这个问题。</p>
<p><img src="/img/quic_intro/quic_intro_3.jpg" alt></p>
<p>如上图所示，RTO 发生后，根据重传的 Packet Number 就能确定精确的 RTT 计算。如果 Ack 的 Packet Number 是 N+M，就根据重传请求计算采样 RTT。如果 Ack 的 Pakcet Number 是 N，就根据原始请求的时间计算采样 RTT，没有歧义性。</p>
<p>但是单纯依靠严格递增的 Packet Number 肯定是无法保证数据的顺序性和可靠性。QUIC 又引入了一个 Stream Offset 的概念。</p>
<p>即一个 Stream 可以经过多个 Packet 传输，Packet Number 严格递增，没有依赖。但是 Packet 里的 Payload 如果是 Stream 的话，就需要依靠 Stream 的 Offset 来保证应用数据的顺序。如错误! 未找到引用源。所示，发送端先后发送了 Pakcet N 和 Pakcet N+1，Stream 的 Offset 分别是 x 和 x+y。</p>
<p>假设 Packet N 丢失了，发起重传，重传的 Packet Number 是 N+2，但是它的 Stream 的 Offset 依然是 x，这样就算 Packet N + 2 是后到的，依然可以将 Stream x 和 Stream x+y 按照顺序组织起来，交给应用程序处理。</p>
<p><img src="/img/quic_intro/quic_intro_4.jpg" alt></p>
<h1 id="不允许-Reneging"><a href="#不允许-Reneging" class="headerlink" title="不允许 Reneging"></a>不允许 Reneging</h1><p>什么叫 Reneging 呢？就是接收方丢弃已经接收并且上报给 SACK 选项的内容 [8]。TCP 协议不鼓励这种行为，但是协议层面允许这样的行为。主要是考虑到服务器资源有限，比如 Buffer 溢出，内存不够等情况。</p>
<p>Reneging 对数据重传会产生很大的干扰。因为 Sack 都已经表明接收到了，但是接收端事实上丢弃了该数据。</p>
<p>QUIC 在协议层面禁止 Reneging，一个 Packet 只要被 Ack，就认为它一定被正确接收，减少了这种干扰。</p>
<h1 id="更多的-Ack-块"><a href="#更多的-Ack-块" class="headerlink" title="更多的 Ack 块"></a>更多的 Ack 块</h1><p>TCP 的 Sack 选项能够告诉发送方已经接收到的连续 Segment 的范围，方便发送方进行选择性重传。</p>
<p>由于 TCP 头部最大只有 60 个字节，标准头部占用了 20 字节，所以 Tcp Option 最大长度只有 40 字节，再加上 Tcp Timestamp option 占用了 10 个字节 [25]，所以留给 Sack 选项的只有 30 个字节。</p>
<p>每一个 Sack Block 的长度是 8 个，加上 Sack Option 头部 2 个字节，也就意味着 Tcp Sack Option 最大只能提供 3 个 Block。</p>
<p>但是 Quic Ack Frame 可以同时提供 256 个 Ack Block，在丢包率比较高的网络下，更多的 Sack Block 可以提升网络的恢复速度，减少重传量。</p>
<h1 id="Ack-Delay-时间"><a href="#Ack-Delay-时间" class="headerlink" title="Ack Delay 时间"></a>Ack Delay 时间</h1><p>Tcp 的 Timestamp 选项存在一个问题 [25]，它只是回显了发送方的时间戳，但是没有计算接收端接收到 segment 到发送 Ack 该 segment 的时间。这个时间可以简称为 Ack Delay。</p>
<p>这样就会导致 RTT 计算误差。如下图：</p>
<p><img src="/img/quic_intro/quic_intro_5.jpg" alt></p>
<ul>
<li>可以认为 TCP 的 RTT 计算：<code>RTT = timestamp2 - timestamp1</code></li>
<li>而 Quic 计算如下：<code>RTT = timestamp2 - timestamp1 - AckDelay</code></li>
</ul>
<p><img src="/img/quic_intro/quic_intro_3.jpg" alt></p>
<p>当然 RTT 的具体计算没有这么简单，需要采样，参考历史数值进行平滑计算，参考如下公式<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">SRTT = SRTT + α(RTT - SRTT)</span><br><span class="line">RTO = μ * SRTT + δ*DevRTT</span><br></pre></td></tr></table></figure></p>
<h1 id="基于-stream-和-connecton-级别的流量控制"><a href="#基于-stream-和-connecton-级别的流量控制" class="headerlink" title="基于 stream 和 connecton 级别的流量控制"></a>基于 stream 和 connecton 级别的流量控制</h1><p>QUIC 的流量控制 [22] 类似 HTTP2，即在 Connection 和 Strea6 级别提供了两种流量控制。为什么需要两类流量控制呢？主要是因为 QUIC 支持多路复用。</p>
<ol>
<li>Stream 可以认为就是一条 HTTP 请求。</li>
<li>Connection 可以类比一条 TCP 连接。多路复用意味着在一7 Connetion 上会同时存在多条 Stream。既需要对单个 Stream 进行控制，又需要针对所有 Stream 进行总体控制。</li>
</ol>
<p>QUIC 实现流量控制的原理比较简单：</p>
<p>通过 window_update 帧告诉对端自己可以接收的字节数，这样发送方就不会发送超过这个数量的数据。</p>
<p>通过 BlockFrame 告诉对端由于流量控制被阻塞了，无法发送数据。</p>
<p>QUIC 的流量控制和 TCP 有点区别，TCP 为了保证可靠性，窗口左边沿向右滑动时的长度取决于已经确认的字节数。如果中间出现丢包，就算接收到了更大序号的 Segment，窗口也无法超过这个序列号。</p>
<p>但 QUIC 不同，就算此前有些 packet 没有接收到，它的滑动只取决于接收到的最大偏移字节数。</p>
<p><img src="/img/quic_intro/quic_intro_6.jpg" alt></p>
<ul>
<li>针对 Stream：<code>可用窗口 = 最大窗口数 - 接收到的最大偏移数</code></li>
<li>针对 Connection：<code>可用窗口 = stream1可用窗口 + stream2可用窗口 + ... + streamN可用窗口</code></li>
</ul>
<p>同样地，STGW 也在连接和 Stream 级别设置了不同的窗口数。</p>
<p>最重要的是，我们可以在内存不足或者上游处理性能出现问题时，通过流量控制来限制传输速率，保障服务可用性。</p>
<h1 id="没有队头阻塞的多路复用"><a href="#没有队头阻塞的多路复用" class="headerlink" title="没有队头阻塞的多路复用"></a>没有队头阻塞的多路复用</h1><p>QUIC 的多路复用和 HTTP2 类似。在一条 QUIC 连接上可以并发发送多个 HTTP 请求 (stream)。但是 QUIC 的多路复用相比 HTTP2 有一个很大的优势。</p>
<p>QUIC 一个连接上的多个 stream 之间没有依赖。这样假如 stream2 丢了一个 udp packet，也只会影响 stream2 的处理。不会影响 stream2 之前及之后的 stream 的处理。</p>
<p>这也就在很大程度上缓解甚至消除了队头阻塞的影响。</p>
<p>多路复用是 HTTP2 最强大的特性 [7]，能够将多条请求在一条 TCP 连接上同时发出去。但也恶化了 TCP 的一个问题，队头阻塞 [11]，如下图示：</p>
<p><img src="/img/quic_intro/quic_intro_7.jpg" alt></p>
<p>HTTP2 在一个 TCP 连接上同时发送 4 个 Stream。其中 Stream1 已经正确到达，并被应用层读取。但是 Stream2 的第三个 tcp segment 丢失了，TCP 为了保证数据的可靠性，需要发送端重传第 3 个 segment 才能通知应用层读取接下去的数据，虽然这个时候 Stream3 和 Stream4 的全部数据已经到达了接收端，但都被阻塞住了。</p>
<p>不仅如此，由于 HTTP2 强制使用 TLS，还存在一个 TLS 协议层面的队头阻塞 [12]。</p>
<p><img src="/img/quic_intro/quic_intro_8.jpg" alt></p>
<p>Record 是 TLS 协议处理的最小单位，最大不能超过 16K，一些服务器比如 Nginx 默认的大小就是 16K。由于一个 record 必须经过数据一致性校验才能进行加解密，所以一个 16K 的 record，就算丢了一个字节，也会导致已经接收到的 15.99K 数据无法处理，因为它不完整。</p>
<p>那 QUIC 多路复用为什么能避免上述问题呢？</p>
<ol>
<li>QUIC 最基本的传输单元是 Packet，不会超过 MTU 的大小，整个加密和认证过程都是基于 Packet 的，不会跨越多个 Packet。这样就能避免 TLS 协议存在的队头阻塞。</li>
<li>Stream 之间相互独立，比如 Stream2 丢了一个 Pakcet，不会影响 Stream3 和 Stream4。不存在 TCP 队头阻塞。</li>
</ol>
<p><img src="/img/quic_intro/quic_intro_9.jpg" alt></p>
<p>当然，并不是所有的 QUIC 数据都不会受到队头阻塞的影响，比如 QUIC 当前也是使用 Hpack 压缩算法 [10]，由于算法的限制，丢失一个头部数据时，可能遇到队头阻塞。</p>
<p>总体来说，QUIC 在传输大量数据时，比如视频，受到队头阻塞的影响很小。</p>
<h1 id="加密认证的报文"><a href="#加密认证的报文" class="headerlink" title="加密认证的报文"></a>加密认证的报文</h1><p>TCP 协议头部没有经过任何加密和认证，所以在传输过程中很容易被中间网络设备篡改，注入和窃听。比如修改序列号、滑动窗口。这些行为有可能是出于性能优化，也有可能是主动攻击。</p>
<p>但是 QUIC 的 packet 可以说是武装到了牙齿。除了个别报文比如 PUBLIC_RESET 和 CHLO，所有报文头部都是经过认证的，报文 Body 都是经过加密的。</p>
<p>这样只要对 QUIC 报文任何修改，接收端都能够及时发现，有效地降低了安全风险。</p>
<p>如下图所示，红色部分是 Stream Frame 的报文头部，有认证。绿色部分是报文内容，全部经过加密。</p>
<p><img src="/img/quic_intro/quic_intro_10.jpg" alt></p>
<h1 id="连接迁移"><a href="#连接迁移" class="headerlink" title="连接迁移"></a>连接迁移</h1><p>一条 TCP 连接 [17] 是由四元组标识的（源 IP，源端口，目的 IP，目的端口）。什么叫连接迁移呢？就是当其中任何一个元素发生变化时，这条连接依然维持着，能够保持业务逻辑不中断。当然这里面主要关注的是客户端的变化，因为客户端不可控并且网络环境经常发生变化，而服务端的 IP 和端口一般都是固定的。</p>
<p>比如大家使用手机在 WIFI 和 4G 移动网络切换时，客户端的 IP 肯定会发生变化，需要重新建立和服务端的 TCP 连接。</p>
<p>又比如大家使用公共 NAT 出口时，有些连接竞争时需要重新绑定端口，导致客户端的端口发生变化，同样需要重新建立 TCP 连接。</p>
<p>针对 TCP 的连接变化，MPTCP[5] 其实已经有了解决方案，但是由于 MPTCP 需要操作系统及网络协议栈支持，部署阻力非常大，目前并不适用。</p>
<p>所以从 TCP 连接的角度来讲，这个问题是无解的。</p>
<p>那 QUIC 是如何做到连接迁移呢？很简单，任何一条 QUIC 连接不再以 IP 及端口四元组标识，而是以一个 64 位的随机数作为 ID 来标识，这样就算 IP 或者端口发生变化时，只要 ID 不变，这条连接依然维持着，上层业务逻辑感知不到变化，不会中断，也就不需要重连。</p>
<p>由于这个 ID 是客户端随机产生的，并且长度有 64 位，所以冲突概率非常低。</p>
<h1 id="其他亮点"><a href="#其他亮点" class="headerlink" title="其他亮点"></a>其他亮点</h1><p>此外，QUIC 还能实现前向冗余纠错，在重要的包比如握手消息发生丢失时，能够根据冗余信息还原出握手消息。</p>
<p>QUIC 还能实现证书压缩，减少证书传输量，针对包头进行验证等。</p>
<p>限于篇幅，本文不再详细介绍，有兴趣的可以参考文档 [23] 和文档 [4] 和文档 [26]。</p>

          
        
      


      

    
      <footer class="post-footer">
        

        

        

        
        
          <div class="post-eof"></div>
        
      </footer>
      
    </div>
    
    
    

    

    

    

  </div>
  
  
  
  </article>


      
    
      
        

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://hulinhong.com/2021/02/16/self_cultivation_tcp/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="no5ix">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/uploads/avatar.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="烫">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2021/02/16/self_cultivation_tcp/" itemprop="url">服务器开发自我修养专栏-TCP详解</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2021-02-16T19:08:06+00:00">
                2021-02-16
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Self-cultivation/" itemprop="url" rel="index">
                    <span itemprop="name">Self-cultivation</span>
                  </a>
                </span>

                
                
              
            </span>
          

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    




    
    
    
    <div class="post-body" itemprop="articleBody">
      
      

      

      
      
        <div class="post-eof"></div>
      

      
      

      
        
          
            <h1 id="TCP"><a href="#TCP" class="headerlink" title="TCP"></a>TCP</h1><p>包头长度 20个字节</p>
<h2 id="三次握手"><a href="#三次握手" class="headerlink" title="三次握手"></a>三次握手</h2><p><img src="/img/noodle_plan/tcp/tcp_3_handshake.jpg" alt></p>
<h3 id="如果第三次握手的ack丢失了咋办"><a href="#如果第三次握手的ack丢失了咋办" class="headerlink" title="如果第三次握手的ack丢失了咋办"></a>如果第三次握手的ack丢失了咋办</h3><p>当客户端收到服务端的SYNACK应答后，其状态变为ESTABLISHED，并会发送ACK包给服务端，准备发送数据了。如果此时ACK在网络中丢失（如上图所示），过了超时计时器后，那么服务端会重新发送SYNACK包，重传次数根据/proc/sys/net/ipv4/tcp_synack_retries来指定，默认是5次。如果重传指定次数到了后，仍然未收到ACK应答，那么一段时间后，Server自动关闭这个连接。</p>
<p>问题就在这里，客户端已经认为连接建立，而服务端则可能处在SYN-RCVD或者CLOSED，接下来我们需要考虑这两种情况下服务端的应答：</p>
<ul>
<li>服务端处于CLOSED，当接收到连接已经关闭的请求时，服务端会返回RST 报文，客户端接收到后就会关闭连接，如果需要的话则会重连，那么那就是另一个三次握手了。</li>
<li>服务端处于SYN-RCVD，此时如果接收到正常的ACK 报文，那么很好，连接恢复，继续传输数据；如果接收到写入数据等请求呢？注意了，此时写入数据等请求也是带着ACK 报文的，实际上也能恢复连接，使服务器恢复到ESTABLISHED状态，继续传输数据。</li>
</ul>
<h3 id="SYN-Flood与SYN-Cookie"><a href="#SYN-Flood与SYN-Cookie" class="headerlink" title="SYN-Flood与SYN-Cookie"></a>SYN-Flood与SYN-Cookie</h3><p>所谓SYN-Flood(SYN 洪泛攻击)，就是利用SYNACK 报文的时候，服务器会为客户端请求分配缓存，那么黑客（攻击者），就可以使用一批虚假的ip向服务器大量地发建立TCP 连接的请求，服务器为这些虚假ip分配了缓存后，处在SYN_RCVD状态，存放在半连接队列中；另外，服务器发送的请求又不可能得到回复（ip都是假的，能回复就有鬼了），只能不断地重发请求，直到达到设定的时间/次数后，才会关闭。</p>
<p>服务器不断为这些半开连接分配资源，导致服务器的连接资源被消耗殆尽，不过所幸，我们可以使用SYN Cookie进行稍微的防御一下。</p>
<p>所谓的<strong>SYN Cookie防御系统</strong>，与前面接收到SYN 报文就分配缓存不同，此时暂不分配资源；同时利用SYN 报文的源和目的地IP和端口，以及服务器存储的一个秘密数，使用它们进行散列，得到server_isn作为服务端的初始 TCP 序号，也就是所谓的SYN cookie, 然后将SYNACK 报文中发送给客户端，接下来就是对ACK 报文进行判断，如果其返回的ack里的确认号正好等于server_isn + 1，说明这是一个合法的ACK，那么服务器才会为其生成一个具有套接字的全开的连接。(有点类似于<a href="#JWT">JWT</a>那一套机制哈)</p>
<p>缺点: </p>
<ul>
<li>增加了密码学运算, 增大了cpu消耗</li>
<li>因为没有保存半连接状态, 所以无法存储一些比如大窗口/sack等信息</li>
</ul>
<h2 id="四次挥手"><a href="#四次挥手" class="headerlink" title="四次挥手"></a>四次挥手</h2><p><img src="/img/noodle_plan/tcp/tcp_4_handshake.jpg" alt></p>
<h3 id="timewait的意义"><a href="#timewait的意义" class="headerlink" title="timewait的意义"></a>timewait的意义</h3><ul>
<li>2msl之后网络中的数据分节全部消失, 防止影响到复用了原端口ip的新连接</li>
<li>如果b没收到最后一个ack, b就会重发fin, a如果不维护一个timewait却收到了一个fin会感觉莫名其妙然后响应一个rst, 然后b就会解释为一个错误</li>
</ul>
<h2 id="timewait和closewait太多咋办"><a href="#timewait和closewait太多咋办" class="headerlink" title="timewait和closewait太多咋办"></a>timewait和closewait太多咋办</h2><ul>
<li>timewait太多咋办? <ul>
<li>net.ipv4.tcp_tw_reuse = 1 表示开启重用。允许将TIME-WAIT sockets重新用于新的TCP连接，默认为0，表示关闭；</li>
<li>net.ipv4.tcp_tw_recycle = 1 表示开启TCP连接中TIME-WAIT sockets的快速回收，默认为0，表示关闭。</li>
<li>net.ipv4.tcp_fin_timeout这个时间可以减少在异常情况下服务器从FIN-WAIT-2转到TIME_WAIT的时间。 </li>
</ul>
</li>
<li>closewait太多咋办?<ul>
<li>解决方案只有: 查代码. 因为如果一直保持在CLOSE_WAIT状态，那么只有一种情况，就是在对方关闭连接之后服务器程序自己没有进一步发出fin信号。换句话说，就是在对方连接关闭之后，程序里没有检测到，或者由于什么逻辑bug导致服务端没有主动发起close, 或者程序压根就忘记了这个时候需要关闭连接，于是这个资源就一直被程序占着。</li>
</ul>
</li>
</ul>
<h2 id="tcp拥塞控制"><a href="#tcp拥塞控制" class="headerlink" title="tcp拥塞控制"></a>tcp拥塞控制</h2><p><img src="/img/noodle_plan/tcp/tcp_congestion_control.png" alt></p>
<ul>
<li>快速重传:<br>  报文段1成功接收并被确认ACK 2，接收端的期待序号为2，当报文段2丢失，报文段3失序到来，与接收端的期望不匹配，接收端重复发送冗余ACK 2。这样，如果在超时重传定时器溢出之前，接收到连续的三个重复冗余ACK（其实是收到4个同样的ACK，第一个是正常的，后三个才是冗余的），发送端便知晓哪个报文段在传输过程中丢失了，于是重发该报文段，不需要等待超时重传定时器溢出，大大提高了效率。这便是快速重传机制。</li>
<li>快速恢复</li>
<li>慢启动</li>
<li>拥塞避免</li>
</ul>
<h2 id="tcp滑动窗口"><a href="#tcp滑动窗口" class="headerlink" title="tcp滑动窗口"></a>tcp滑动窗口</h2><p><img src="/img/noodle_plan/tcp/tcp_sliding_window1.png" alt></p>
<p>每个TCP连接的两端都维护一组窗口：发送窗口结构（send window structure）和接收窗口结构（receive window structure）。TCP以字节为单位维护其窗口结构。TCP头部中的窗口大小字段相对ACK号有一个字节的偏移量。发送端计算其可用窗口，即它可以立即发送的数据量。可用窗口（允许发送但还未发送）计算值为提供窗口（即由接收端通告的窗口）大小减去在传（已发送但未得到确认）的数据量。图中P1、P2、P3分别记录了窗口的左边界、下次发送的序列号、右边界。</p>
<p><img src="/img/noodle_plan/tcp/tcp_sliding_window2.png" alt></p>
<p>如上图所示， 随着发送端接收到返回的数据ACK，滑动窗口也随之右移。发送端根据接收端返回的ACK可以得到两个重要的信息：一是接收端期望收到的下一个字节序号；二是当前的窗口大小（再结合发送端已有的其他信息可以得出还能发送多少字节数据）。</p>
<p>需要注意的是：发送窗口的左边界只能右移，因为它控制的是已发送并受到确认的数据，具有累积性，不能返回；右边界可以右移也可以左移（能左移的右边界会带来一些缺陷，下文会讲到）。</p>
<p>接收端也维护一个窗口结构，但比发送窗口简单（只有左边界和右边界）。该窗口结构记录了已接收并确认的数据，以及它能够接收的最大序列号，该窗口能保证接收数据的正确性（避免存储重复的已接收和确认的数据，以及避免存储不应接收的数据）。由于TCP的累积ACK特性，只有当到达数据序列号等于左边界时，窗口才能向前滑动。</p>
<h3 id="零窗口与TCP持续计时器"><a href="#零窗口与TCP持续计时器" class="headerlink" title="零窗口与TCP持续计时器"></a>零窗口与TCP持续计时器</h3><p><img src="/img/noodle_plan/tcp/tcp_sliding_window3.png" alt></p>
<p>Zero Window  </p>
<p>上图，我们可以看到一个处理缓慢的Server（接收端）是怎么把Client（发送端）的TCP Sliding Window给降成0的。此时，你一定会问，如果Window变成0了，TCP会怎么样？是不是发送端就不发数据了？是的，发送端就不发数据了，你可以想像成“Window Closed”，那你一定还会问，如果发送端不发数据了，接收方一会儿Window size 可用了，怎么通知发送端呢？</p>
<p>解决这个问题，TCP使用了<strong>Zero Window Probe技术</strong>，缩写为ZWP，也就是说，发送端在窗口变成0后，会发ZWP的包给接收方，让接收方来ack他的Window尺寸，一般这个值会设置成3次，第次大约30-60秒（不同的实现可能会不一样）。如果3次过后还是0的话，有的TCP实现就会发RST把链接断了。</p>
<h2 id="ACK延迟确认机制"><a href="#ACK延迟确认机制" class="headerlink" title="ACK延迟确认机制"></a>ACK延迟确认机制</h2><p>接收方在收到数据后，并不会立即回复ACK,而是延迟一定时间。一般ACK延迟发送的时间为200ms，但这个200ms并非收到数据后需要延迟的时间。系统有一个固定的定时器每隔200ms会来检查是否需要发送ACK包。这样做有两个目的。</p>
<ul>
<li>这样做的目的是ACK是可以合并的，也就是指如果连续收到两个TCP包，并不一定需要ACK两次，只要回复最终的ACK就可以了，可以降低网络流量。</li>
<li>如果接收方有数据要发送，那么就会在发送数据的TCP数据包里，带上ACK信息。这样做，可以避免大量的ACK以一个单独的TCP包发送，减少了网络流量。</li>
</ul>

          
        
      


      

    
      <footer class="post-footer">
        

        

        

        
        
          <div class="post-eof"></div>
        
      </footer>
      
    </div>
    
    
    

    

    

    

  </div>
  
  
  
  </article>


      
    
  </section>

  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/page/4/"><i class="fa fa-angle-left"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/4/">4</a><span class="page-number current">5</span><a class="page-number" href="/page/6/">6</a><span class="space">&hellip;</span><a class="page-number" href="/page/48/">48</a><a class="extend next" rel="next" href="/page/6/"><i class="fa fa-angle-right"></i></a>
  </nav>



          </div>
          


          

        </div>
        
          
  
  

  <aside id="sidebar" class="sidebar">

    
      
        <div id="sidebar-dimmer"></div>
      
    

    <div class="sidebar-inner">
    
      <div class="sidebar-toggle-inside motion-element">
        <div class="sidebar-toggle-line-wrap">
          <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
          <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
          <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
        </div>
      </div>

      

      

      <section class="site-overview sidebar-panel sidebar-panel-active">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          <a href="/" class="site-author-image" rel="start" style="border:none">
            <img class="site-author-image" itemprop="image" src="/uploads/avatar.png" alt="no5ix">
          </a>
          <p class="site-author-name" itemprop="name">no5ix</p>
           
              <p class="site-description motion-element" itemprop="description">推荐使用Chrome/Firefox/Safari阅读本博客. 以前的老笔记将会一篇一篇慢慢整理为博客, 这既启发了他人, 也锻炼了自己的描述交流能力.</p>
          
        </div>

        <nav class="site-state motion-element">

          
            
            
            <div class="site-state-item site-state-categories">
              <a href="/categories/index.html">
                <span class="site-state-item-count">12</span>
                <span class="site-state-item-name">分类</span>
              </a>
            </div>
          

          
            <div class="site-state-item site-state-posts">
              <a href="/archives/">
                <span class="site-state-item-count">237</span>
                <span class="site-state-item-name">日志</span>
              </a>
            </div>
          

          
            
            
            <div class="site-state-item site-state-tags">
              <a href="/tags/index.html">
                <span class="site-state-item-count">91</span>
                <span class="site-state-item-name">标签</span>
              </a>
            </div>
          

          <div class="site-state-item site-state-about">
            <a href="/about/">
              <span class="site-state-item-about fa fa-fw fa-user"></span>
              <span class="site-state-item-name">关于</span>
            </a>
          </div>
          
        </nav>

        

        <div class="links-of-author motion-element">
          
          
          <!-- 网易云音乐 -->
            <!-- <div class="netease-cloud-music"> -->
              <!-- <iframe frameborder="no" border="0" marginwidth="0" marginheight="0" width=280 height=110 src="//music.163.com/outchain/player?type=0&id=992743594&auto=0&height=90"></iframe> -->
            <!-- </div> -->
          <!-- 网易云音乐 -->

        </div>

        
        

        
        
          <div class="links-of-blogroll motion-element links-of-blogroll-block">
            <div class="links-of-blogroll-title">
              <i class="fa  fa-fw fa-globe"></i>
              友情链接
            </div>
            <ul class="links-of-blogroll-list">
              
                <li class="links-of-blogroll-item">
                  <a href="http://119.23.17.57" title="ksun的博客" target="_blank">ksun的博客</a>
                </li>
              
                <li class="links-of-blogroll-item">
                  <a href="https://mp.weixin.qq.com/mp/homepage?__biz=MzU3MTUyNzg0NQ==&hid=1&sn=7a3ae61b7af714f75d68e7ae826a2d2c&scene=18#wechat_redirect" title="你有图么我有故事" target="_blank">你有图么我有故事</a>
                </li>
              
            </ul>
          </div>
        

        

        


      </section>

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">
  
  &copy;  2013 - 
  <span itemprop="copyrightYear">2023</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">no5ix</span>
</div>



        

        
      </div>
    </footer>

    <!--
    <div class="back-to-top">
      <i class="fa fa-arrow-up"></i>
      
        <span id="scrollpercent"><span>0</span>%</span>
      
    </div>
    -->

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/fancybox/dist/jquery.fancybox.js?v=3.2.10"></script>


  




  <script type="text/javascript" src="/js/src/utils.js?v=5.1.2"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.2"></script>


  
  

  
    <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.2"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.2"></script>

  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.2"></script>



  


  




	





  





  






  

  <script type="text/javascript">

    var is_load_xml_finished = 0;

    var searchFunc = function (path, search_id, content_id) {
      // 0x00. environment initialization
      'use strict';

      var $input = document.getElementById(search_id);
      var $resultContent = document.getElementById(content_id);
      // var datas = [];

      /* loading css1 : Dot Css Loader*/
      var DotLoader = "<div class='loader'>Loading...</div>";

      /* loading css2 : Pure Css Loader - Square */
      var SquareLoader = 
        "<div class='loader'>" +
          "<div class='square' ></div>" +
          "<div class='square'></div>" +
          "<div class='square last'></div>" +
          "<div class='square clear'></div>" +
          "<div class='square'></div>" +
          "<div class='square last'></div>" +
          "<div class='square clear'></div>" +
          "<div class='square '></div>" +
          "<div class='square last'></div>" +
        "</div>";

      var ProgressBar = 
          "<div class='progress-bar'>" +
            "<div class='progress-bar-charge'></div>" +
          "</div>";

      var str = "";
      var keywords = [];
      var temp_keyword = "";

      // 是否为第一个字母被键入的标志位
      var first_char_flag = 0;

      // 因为在移动设备上, 点击搜索之后会 scroll 到页面顶部, 所以需要记录之前的页面x, y坐标值, 以便于搜索完点击 close 按钮之后 scroll 回原来的页面坐标值.
      var last_page_x = 0;
      var last_page_y = 0;

      var local_search_tips = 
            "<span class='local-search-empty'>" + "第一次搜索可能较慢, 先思考一个经典算法问题, 跳台阶:" + "</span>" +
            "<span class='local-search-empty'>" + "一只青蛙一次可以跳上1级台阶，也可以跳上2级。求该青蛙跳上一个6级的台阶总共有多少种跳法?n级呢?" + "</span>";

      function CloseLocalSearch()
      {
        first_char_flag = 0;

        $('#local-search-input').val('');
        $('#local-search-close').hide();

        // $('.local-search-result-cls ul li').velocity('stop').velocity('transition.slideDownOut', 200);

        $('#' + content_id).attr("headroom_special_attr","true"); 
        
        if (isMobile())
        {
          // $('body').scrollTop(last_page_y);  // scrollTop 有兼容性问题
          scrollTo(last_page_x, last_page_y);

          $('#' + content_id).hide();
        }
        else
        {
          $('#' + content_id).velocity('stop').velocity( 'transition.bounceUpOut', 200 );
        }

        // $('#' + content_id).velocity('stop').velocity( isMobile() ? 'transition.fadeOut' : 'transition.bounceUpOut', {
        //   // delay: isMobile() ? 50 : 0,
        //   duration: isMobile() ? 500 : 200,
        //   // begin: function() { 
        //   //   if (isMobile())
        //   //   {
        //   //     $('body').scrollTop(last_page_y);
        //   //   } 
        //   // }
        //   complete: function () {
        //     if (isMobile())
        //     {
        //       if (last_page_y < 20000)
        //       {
        //         $('body').velocity('scroll', { offset: last_page_y+"px", duration: last_page_y < 10000 ? 1000 : 2000 });
        //       }
        //       else
        //       {
        //         $('body').scrollTop(last_page_y);
        //       }
        //       // $('body').velocity('scroll');

        //       // $('html,body').animate({
        //       //   scrollTop: last_page_y
        //       // },400);
        //       // $('body').velocity('transition.slideDownIn', 1000);
        //       // $('body').velocity('scroll', { offset: last_page_y+"px", duration: document.body.scrollHeight < 20000 ? 1500 : 3000 });
        //     }
        //   }
        // });
      }

      function handleSearch()
      {
        if (keywords.length <= 0) {
          return;
        }
        $resultContent.innerHTML = "";
        $('#local-search-close').show();

        // 0x04. perform local searching
        if (is_load_xml_finished == 0)
        {
          $resultContent.innerHTML = 
            "<ul class='local-search-empty-ul'>" + 
            local_search_tips +
            ProgressBar;
        }
        else
        {
          // Retrieve the object from local storage
          var xml_resp = retrieve_search_xml()

          xml_resp.forEach(function (data) {
          // datas.forEach(function (data) {
            var isMatch = true;
            var content_index = [];
            if (!data.title || data.title.trim() === '') {
              data.title = "Untitled";
            }
            var is_encrypted = data.encrypted.trim() == '1'
            var is_sensitive = CONFIG.local_search.sensitive_word && data_content.indexOf(CONFIG.local_search.sensitive_word) >= 0
            var orig_data_title = data.title.trim();
            var data_title = orig_data_title.toLowerCase();
            var orig_data_content = data.content.trim().replace(/<[^>]+>/g, "");
            var data_content = orig_data_content.toLowerCase();
            var data_url = decodeURIComponent(data.url);
            var index_title = -1;
            var index_content = -1;
            var first_occur = -1;
            // only match artiles with not empty contents
            if (data_content !== '') {
              keywords.forEach(function (keyword, i) {
                index_title = data_title.indexOf(keyword);
                index_content = (is_sensitive || is_encrypted) ? -1 : data_content.indexOf(keyword);

                if (index_title < 0 && index_content < 0) {
                  isMatch = false;
                } else {
                  if (index_content < 0) {
                    index_content = 0;
                  }
                  if (i == 0) {
                    first_occur = index_content;
                  }
                  // content_index.push({index_content:index_content, keyword_len:keyword_len});
                }
              });
            } else {
              isMatch = false;
            }
            // 0x05. show search results
            if (isMatch) {
              var content = orig_data_content;
              if (first_occur >= 0) {
                var match_content = "";
                if (!is_sensitive && !is_encrypted)
                {
                  // cut out 100 characters
                  var start = first_occur - 20;
                  var end = first_occur + 80;

                  if (start < 0) {
                    start = 0;
                  }

                  if (start == 0) {
                    end = 100;
                  }

                  if (end > content.length) {
                    end = content.length;
                  }

                  match_content = content.substr(start, end);
                }

                // highlight all keywords
                var regS = "";
                if (match_content != "")
                {
                  keywords.forEach(function (keyword) {
                    regS = new RegExp(keyword, "gi");
                    match_content = match_content.replace(regS, "<b class=\"search-keyword\">" + keyword + "</b>");
                    orig_data_title = orig_data_title.replace(regS, "<b class=\"search-keyword\">" + keyword + "</b>");
                  });
                }
                else
                {
                  keywords.forEach(function (keyword) {
                    regS = new RegExp(keyword, "gi");
                    orig_data_title = orig_data_title.replace(regS, "<b class=\"search-keyword\">" + keyword + "</b>");
                  });
                }
                str += "<li><a href='" + data_url + "' class='search-result-title' target='_blank'>" + orig_data_title + "</a>";
                str += "<p class=\"search-result\">" + match_content + "...</p>"
              }
              str += "</li>";
            }
          });

          str += "</ul>";
          if (str.indexOf('<li>') === -1) {
            return $resultContent.innerHTML = 
              "<ul class='local-search-empty-ul'><span class='local-search-empty'>找不到, 换个搜索关键字试一哈.<span></ul>";
          }
          $resultContent.innerHTML = str;
        }
      }

      $input.addEventListener('input', function () {
        // 0x03. parse query to keywords list
        str = '<ul class=\"search-result-list\">';
        temp_keyword = this.value.trim();
        if (temp_keyword.length <= 0) {
          CloseLocalSearch();
          return;
        }

        keywords = temp_keyword.toLowerCase().split(/[\s\-]+/);
        handleSearch();

        // 当用户键入第一个字母的时候的动画处理逻辑 : 
        // 当 first_char_flag 为 0 的时候, 
        // 要播放一个动画
        if (first_char_flag == 0)
        {
            // $('body').scrollTop(0);
          if (isMobile())
          {
            last_page_x = window.pageXOffset;
            last_page_y = window.pageYOffset;
            // $('body').scrollTop(0);
            scrollTo(0,0);

          }
          first_char_flag = 1;
          $('#' + content_id).removeAttr("headroom_special_attr");
          
          $('#' + content_id).velocity('stop').velocity('transition.slideDownIn', 300);

          $('.local-search-result-cls ul li').velocity('stop').velocity('transition.slideDownIn', 1000);
        }
      });


      var local_search_xml_data = localStorage.getItem('local_search_xml_data');
      if (!local_search_xml_data) {
        $.ajax({
          // 0x01. load xml file
          url: path,
          dataType: "xml",
          success: function (xmlResponse) {
            store_search_xml(xmlResponse);

            // setTimeout(function(){
            //   is_load_xml_finished = 1;

            //   handleSearch();
            //   $('.local-search-result-cls ul li').velocity('stop').velocity('transition.slideDownIn', 800);
            // }, 2000);
            
            // is_load_xml_finished = 1;

            handleSearch();
            $('.local-search-result-cls ul li').velocity('stop').velocity('transition.slideDownIn', 800);
          }
        });
      }

      $(document).on('click', '#local-search-close', function() {
        CloseLocalSearch();
      });

      $(document).keyup(function(event){
        switch(event.keyCode) {
          case 27:
            // alert("ESC");
            CloseLocalSearch();
        }
      });

      // $(document).on('blur', '#local-search-input', function(e) {
      //   // console.log(document.activeElement.getAttribute('class'));
        
      //   if (isMobile() == false)
      //   {
      //     CloseLocalSearch();
      //   }
      // });
    }

    function isMobile() {
      // console.log(document.body.clientWidth);
      return document.body.clientWidth < 768

      // var userAgent = window.navigator.userAgent;

      // var isiPad = userAgent.match(/iPad/i) !== null;
      // var mobileUA = [
      //   'iphone', 'android', 'phone', 'mobile',
      //   'wap', 'netfront', 'x11', 'java', 'opera mobi',
      //   'opera mini', 'ucweb', 'windows ce', 'symbian',
      //   'symbianos', 'series', 'webos', 'sony',
      //   'blackberry', 'dopod', 'nokia', 'samsung',
      //   'palmsource', 'xda', 'pieplus', 'meizu',
      //   'midp' ,'cldc' , 'motorola', 'foma',
      //   'docomo', 'up.browser', 'up.link', 'blazer',
      //   'helio', 'hosin', 'huawei', 'novarra',
      //   'coolpad', 'webos', 'techfaith', 'palmsource',
      //   'alcatel', 'amoi', 'ktouch', 'nexian',
      //   'ericsson', 'philips', 'sagem', 'wellcom',
      //   'bunjalloo', 'maui', 'smartphone', 'iemobile',
      //   'spice', 'bird', 'zte-', 'longcos',
      //   'pantech', 'gionee', 'portalmmm', 'jig browser',
      //   'hiptop', 'benq', 'haier', '^lct',
      //   '320x320', '240x320', '176x220'
      // ];
      // var pattern = new RegExp(mobileUA.join('|'), 'i');

      // return !isiPad && userAgent.match(pattern);
    }

    function store_search_xml(xmlResponse) {
        datas = $("entry", xmlResponse).map(function () {
          return {
            title: $("title", this).text(),
            content: $("content", this).text(),
            url: $("url", this).text(),
            encrypted: $("encrypted", this).text(),
          };
        }).get();
        // Put the object into storage
        localStorage.setItem('local_search_xml_data', JSON.stringify(datas));
        is_load_xml_finished = 1;

        console.log("store search.xml finished.");
    }

    function ajax_store_search_xml() {
      $.ajax({
        url: "/search.xml",
        dataType: "xml",
        success: function (xmlResponse) {
            store_search_xml(xmlResponse);
        }
      });
    }

    function retrieve_search_xml() {
        // Retrieve the object from local storage
        var retrievedObject = localStorage.getItem('local_search_xml_data');
        var xml_resp = JSON.parse(retrievedObject)
        return xml_resp
    }

    var getSearchFile = function(){
      var path = "/search.xml";
      var local_search_result_name = isMobile() ? "local-search-result-mobile" : "local-search-result-pc";
      searchFunc(path, 'local-search-input', local_search_result_name);
    }

    var local_search_xml_data = localStorage.getItem('local_search_xml_data');
    if (local_search_xml_data) {
      is_load_xml_finished = 1;
      console.log("load search.xml finished.");
    }
    var last_use_local_search_date = localStorage.getItem('last_use_local_search_date');
    var curDate = new Date();
    // 只有在 localStorage 没有 search.xml数据或者 距离上次使用local search已经超过一天了才去取search.xml
    // 节省流量
    if (last_use_local_search_date != curDate.getDate() || !local_search_xml_data) {
      // preload search.xml
      ajax_store_search_xml();
    }

    localStorage.setItem('last_use_local_search_date', curDate.getDate());
    

  </script>





  

  

  

  

  

  


  <script type="text/javascript" src="/lib/wobble_window/wobblewindow.js"> </script>
<script type="text/javascript" src="/js/src/custom.js"></script>
</body>
</html>


<!-- 页面点击小红心 -->





<script type="text/javascript" src="/js/src/headroom.js"></script> 

<!-- 代码块复制功能 -->
<script type="text/javascript" src="/js/src/clipboard-use.js"></script>
